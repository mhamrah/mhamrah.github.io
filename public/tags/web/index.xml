<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> </title>
    <link>http://blog.michaelhamrah.com/tags/web/</link>
    <language>en-us</language>
    <author>Michael Hamrah</author>
    <rights>(C) 2015</rights>
    <updated>2014-05-24 00:00:00 &#43;0000 UTC</updated>

    
      
        <item>
          <title>Spray Directives: Creating Your Own, Simple Directive</title>
          <link>http://blog.michaelhamrah.com/2014/05/spray-directives-creating-your-own-simple-directive/</link>
          <pubDate>Sat, 24 May 2014 00:00:00 UTC</pubDate>
          <author>Michael Hamrah</author>
          <guid>http://blog.michaelhamrah.com/2014/05/spray-directives-creating-your-own-simple-directive/</guid>
          <description>&lt;p&gt;The &lt;a href=&#34;http://spray.io/documentation/1.2.1/spray-routing/&#34;&gt;spray-routing&lt;/a&gt; package provides an excellent dsl for creating restful api&amp;#8217;s with Scala and Akka. This dsl is powered by &lt;a href=&#34;http://spray.io/documentation/1.2.1/spray-routing/key-concepts/directives/&#34;&gt;directives&lt;/a&gt;, small building blocks you compose to filter, process and compose requests and responses for your API. Building your own directives lets you create reusable components for your application and better organize your application.&lt;/p&gt;

&lt;p&gt;I recently refactored some code in a Spray API to leverage custom directives. The &lt;a href=&#34;http://spray.io/documentation/1.2.1/spray-routing/advanced-topics/custom-directives/&#34;&gt;Spray documentation provides a good reference on custom directives&lt;/a&gt; but I found myself getting hung up in a few places.&lt;/p&gt;

&lt;p&gt;As an example we&amp;#8217;re going to write a custom directive which produces a UUID for each request. Here&amp;#8217;s how I want to use this custom directive:&lt;/p&gt;

&lt;pre class=&#34;syntax scala&#34;&gt;generateUUID { uuid =&gt;
  path(&#34;foo&#34;) {
   get {
     //log the uuid, pass it to your app, or maybe just return it
     complete { uuid.toString }
   }
  }
}
&lt;/pre&gt;

&lt;p&gt;Usually you leverage existing directives to build custom directives. I (incorrectly) started with the &lt;code&gt;provide&lt;/code&gt; directive to provide a value to an inner route:&lt;/p&gt;

&lt;pre class=&#34;syntax scala&#34;&gt;import spray.routing._
import java.util.UUID
import Directives._

trait UuidDirectives {
  def generateUuid: Directive1[UUID] = {
    provide(UUID.randomUUID)
  }
}
&lt;/pre&gt;

&lt;p&gt;Before I explain what&amp;#8217;s wrong, let&amp;#8217;s dig into the code. First, generateUuid is a function which returns a Directive1 wrapping a UUID value. Directive1 is just a type alias for &lt;code&gt;Directive[UUID :: HNil]&lt;/code&gt;. Directives are centered around a feature of the shapeless library called heterogeneous lists, or HLists. An &lt;code&gt;HList&lt;/code&gt; is simply a list, but each element in the list can be a different, specific type. Instead of a generic &lt;code&gt;List[Any]&lt;/code&gt;, your list can be composed of specific types of list of String, Int, String, UUID. The first element of this list is a String, not an Any, and the second is an Int, with all the features of an Int. In the directive above I just have an &lt;code&gt;HList&lt;/code&gt; with one element: &lt;code&gt;UUID&lt;/code&gt;. If I write &lt;code&gt;Directive[UUID :: String :: HNil]&lt;/code&gt; I have a two element list of &lt;code&gt;UUID&lt;/code&gt; and String, and the compiler will throw an error if I try to use this directive with anything other a &lt;code&gt;UUID&lt;/code&gt; and a String. HLists sound like a lightweight case class, but with an &lt;code&gt;HList&lt;/code&gt;, you get a lot of list-like features. HLists allow the compiler to do the heavy lifting of type safety, so you can have strongly-typed functions to compose together.&lt;/p&gt;

&lt;p&gt;Provide is a directive which (surprise surprise) will provide a value to an inner route. I thought this would be perfect for my directive, and the corresponding test ensures it works:&lt;/p&gt;

&lt;pre class=&#34;syntax scala&#34;&gt;import org.scalatest._
import org.scalatest.matchers._
import spray.testkit.ScalatestRouteTest
import spray.http._
import spray.routing.Directives._

class UuidDirectivesSpec
  extends FreeSpec
  with Matchers
  with UuidDirectives
  with ScalatestRouteTest {

  &#34;The UUID Directive&#34; - {
    &#34;can generate a UUID&#34; in {
      Get() ~&gt; generateUuid { uuid =&gt; complete(uuid.toString) } ~&gt; check  {
        responseAs[String].size shouldBe 36
      }
    }
  }
}
&lt;/pre&gt;

&lt;p&gt;But there&amp;#8217;s an issue! Spray directives are classes are composed when instantiated via an apply() function. The &lt;a href=&#34;http://spray.io/documentation/1.2.1/spray-routing/advanced-topics/understanding-dsl-structure/&#34;&gt;Spray docs on understanding the dsl structure&lt;/a&gt; explains it best, but in summary, generateUuid will only be called once when the routing tree is built, not on every request.&lt;/p&gt;

&lt;p&gt;A better unit test shows the issue:&lt;/p&gt;

&lt;pre class=&#34;syntax scala&#34;&gt;&#34;will generate different UUID per request&#34; in {
      //like the runtime, instantiate route once
      val uuidRoute =  generateUuid { uuid =&gt; complete(uuid.toString) }

      var uuid1: String = &#34;&#34;
      var uuid2: String = &#34;&#34;
      Get() ~&gt; uuidRoute ~&gt; check  {
        responseAs[String].size shouldBe 36
        uuid1 = responseAs[String]
      }
      Get() ~&gt; uuidRoute ~&gt; check  {
        responseAs[String].size shouldBe 36
        uuid2 = responseAs[String]
      }
      //fails!
      uuid1 shouldNot equal (uuid2)
    }
  }
&lt;/pre&gt;

&lt;p&gt;The fix is simple: we need to use the &lt;code&gt;extract&lt;/code&gt; directive which applies the current RequestContext to our route so it&amp;#8217;s called on every request. For our UUID directive we don&amp;#8217;t need anything from the request, just the function which is run for every request:&lt;/p&gt;

&lt;pre class=&#34;syntax scala&#34;&gt;trait UuidDirectives {
  def generateUuid: Directive[UUID :: HNil] = {
    extract(ctx =&gt;
        UUID.randomUUID)
  }
}
&lt;/pre&gt;

&lt;p&gt;With our randomUUID call wrapped in an extract directive we have a unique call per request, and our tests pass!&lt;/p&gt;

&lt;p&gt;In a following post we&amp;#8217;ll add some more complexity to our custom directive, stay tuned!&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Spray Directives: Custom Directives, Part Two: flatMap</title>
          <link>http://blog.michaelhamrah.com/2014/05/spray-directives-custom-directives-part-two-flatmap/</link>
          <pubDate>Sat, 24 May 2014 00:00:00 UTC</pubDate>
          <author>Michael Hamrah</author>
          <guid>http://blog.michaelhamrah.com/2014/05/spray-directives-custom-directives-part-two-flatmap/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;http://blog.michaelhamrah.com/2014/05/spray-directives-creating-your-own-simple-directive/&#34;&gt;Our last post covered custom Spray Directives&lt;/a&gt;. We&amp;#8217;re going to expand our UUID directive a little further. Generating a unique ID per request is great, but what if we want the client to pass in an existing unique identifier to act as a correlation id between systems?&lt;/p&gt;

&lt;p&gt;We&amp;#8217;ll modify our existing directive by checking to see if the client supplied a correlation-id request-header using the existing &lt;code&gt;optionalHeaderValueByName&lt;/code&gt; directive:&lt;/p&gt;

&lt;pre class=&#34;syntax scala&#34;&gt;def generateUuid: Directive[UUID :: HNil] = {
    optionalHeaderValueByName(&#34;correlation-id&#34;) {
      case Some(value) =&gt; provide(UUID.fromString(value))
      case None =&gt; provide(UUID.randomUUID)
    }
  }
&lt;/pre&gt;

&lt;p&gt;Unfortunately this code doesn&amp;#8217;t compile! We get an error because Spray is looking for a Route, which is a function of RequestContext =&amp;gt; Unit:&lt;/p&gt;

&lt;pre class=&#34;syntax bash&#34;&gt;[error]  found   : spray.routing.Directive1
[error]     (which expands to)  spray.routing.Directive[shapeless.::]
[error]  required: spray.routing.RequestContext =&gt; Unit
[error]       case Some(value) =&gt; provide(UUID.fromString(value))
&lt;/pre&gt;

&lt;p&gt;What do we do? &lt;code&gt;flatMap&lt;/code&gt; comes to the rescue. Here&amp;#8217;s the deal: we need to transform one directive (&lt;code&gt;optionalHeaderValueByName&lt;/code&gt;) into another directive (one that provides a UUID). We do this by using flatMap to focus on the value in the first directive (the option returned from &lt;code&gt;optionalHeaderValueByName&lt;/code&gt;) and return another value (the UUID). With &lt;code&gt;flatMap&lt;/code&gt; we are basically &amp;#8220;repackaging&amp;#8221; one value into another package.&lt;/p&gt;

&lt;p&gt;Here&amp;#8217;s the updated code which properly compiles:&lt;/p&gt;

&lt;pre class=&#34;syntax scala&#34;&gt;def generateUuid: Directive[UUID :: HNil] = {
    //use flatMap to match on the Option returned and provide
    //a new value
    optionalHeaderValueByName(&#34;correlation-id&#34;).flatMap {
      case Some(value) =&gt; provide(UUID.fromString(value))
      case None =&gt; provide(UUID.randomUUID)
    }
  }
&lt;/pre&gt;

&lt;p&gt;and the test:&lt;/p&gt;

&lt;pre class=&#34;syntax scala&#34;&gt;&#34;can extract a uuid value from the header&#34; in {
      val uuid = java.util.UUID.randomUUID.toString

      Get() ~&gt; addHeader(&#34;correlation-id&#34;, uuid) ~&gt; uuidRoute ~&gt; check {
        responseAs[String] shouldEqual uuid
      }
    }
&lt;/pre&gt;

&lt;p&gt;There&amp;#8217;s a small tweak we&amp;#8217;ll make to our UUID directive to show another example of directive composition. If the client doesn&amp;#8217;t supply a UUID, and we call generateUUID multiple times, we&amp;#8217;ll get different uuids for the same request. This defeats the purpose of a single correlation id, and prevents us from extracting a uuid multiple times per request. A failing test shows the issue:&lt;/p&gt;

&lt;pre class=&#34;syntax scala&#34;&gt;&#34;can extract the same uuid twice per request&#34; in {
      var uuid1: String =&#34;&#34;
      var uuid2: String = &#34;&#34;
      Get() ~&gt; generateUuid { uuid =&gt;
        {
          uuid1 = uuid.toString
          generateUuid { another =&gt;
            uuid2 = another.toString
            complete(&#34;&#34;)
          }
        }
      } ~&gt; check {
        //fails
        uuid1 shouldEqual uuid2
      }
    }
&lt;/pre&gt;

&lt;p&gt;To fix the issue, if we generate a UUID, we will add it to the request header as if the client supplied it. We&amp;#8217;ll use the mapRequest directive to add the generated UUID to the header.&lt;/p&gt;

&lt;pre class=&#34;syntax scala&#34;&gt;def generateUuid: Directive[UUID :: HNil] = {
    optionalHeaderValueByName(&#34;correlation-id&#34;).flatMap {
      case Some(value) =&gt; provide(UUID.fromString(value))
      case None =&gt;
        val id = UUID.randomUUID
        mapRequest(r =&gt; r.withHeaders(r.headers :+ RawHeader(&#34;correlation-id&#34;, id.toString))) &amp;#038; provide(id)
    }
  }
&lt;/pre&gt;

&lt;p&gt;In my first version I had the mapRequest call and the provide call on separate lines (there was no &amp;amp;). mapRequest was never being called, and it was because mapRequest was not being returned as a value- only the provide directive is returned. We need to &amp;#8220;merge&amp;#8221; these two directives with the &amp;amp; operator. &lt;code&gt;mapRequest&lt;/code&gt; is a no-op returning a Directive0 (a Directive with a Nil HList) so combining it with provide yields a Directive1[UUID], which is exactly what we want.&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Spray API Development: Getting Started with a Spray Web Service Using JSON</title>
          <link>http://blog.michaelhamrah.com/2013/06/scala-web-apis-up-and-running-with-spray-and-akka/</link>
          <pubDate>Sat, 22 Jun 2013 00:00:00 UTC</pubDate>
          <author>Michael Hamrah</author>
          <guid>http://blog.michaelhamrah.com/2013/06/scala-web-apis-up-and-running-with-spray-and-akka/</guid>
          <description>

&lt;p&gt;&lt;a href=&#34;spray.io&#34;&gt;Spray&lt;/a&gt; is a great library for building http api&amp;#8217;s with Scala. Just like &lt;a href=&#34;playframework.com&#34;&gt;Play!&lt;/a&gt; it&amp;#8217;s built with &lt;a href=&#34;akka.io&#34;&gt;Akka&lt;/a&gt; and provides numerous low and high level tools for http servers and clients. It puts Akka and Scala&amp;#8217;s asynchronous programming model first for high performance, composable application development.&lt;/p&gt;

&lt;p&gt;I wanted to highlight the &lt;a href=&#34;http://spray.io/documentation/1.1-M8/spray-routing/&#34;&gt;spray-routing&lt;/a&gt; library which provides a nice DSL for defining web services. The routing library can be used with the standalone &lt;a href=&#34;http://spray.io/documentation/1.1-M8/spray-can/#spray-can&#34;&gt;spray-can&lt;/a&gt; http server or in any servlet container.&lt;/p&gt;

&lt;p&gt;We&amp;#8217;ll highlight a simple entity endpoint, unmarshalling Json data into an object and deferring actual process to another Akka actor. To get started with your own spray-routing project, I created a &lt;a href=&#34;https://github.com/n8han/giter8&#34;&gt;giter8&lt;/a&gt; template to bootstrap your app:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$g8 mhamrah/sbt -b spray&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://spray.io/documentation/&#34;&gt;The documentation&lt;/a&gt; is quite good and &lt;a href=&#34;https://github.com/spray/spray&#34;&gt;the source code is worth browsing&lt;/a&gt;. For a richer routing example check out &lt;a href=&#34;https://github.com/spray/spray/tree/release/1.1/examples/spray-routing/on-spray-can&#34;&gt;Spray&amp;#8217;s own routing project&lt;/a&gt; which shows off http-streaming and a few other goodies.&lt;/p&gt;

&lt;h2 id=&#34;creating-a-server:e4c25fe8ca10d79600b3f827b4d5c8dd&#34;&gt;Creating a Server&lt;/h2&gt;

&lt;p&gt;We are going to create three main structures: An actor which contains our Http Service, a trait which contains our route definition, and a Worker actor that will do the work of the request.&lt;/p&gt;

&lt;p&gt;The service actor is launched in your application&amp;#8217;s main method. Here we are using Scala&amp;#8217;s App class to launch our server feeding in values from &lt;a href=&#34;https://github.com/typesafehub/config&#34;&gt;typesafe config&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!scala
val service= system.actorOf(Props[SpraySampleActor], &amp;quot;spray-sample-service&amp;quot;)
IO(Http) ! Http.Bind(service, system.settings.config.getString(&amp;quot;app.interface&amp;quot;), system.settings.config.getInt(&amp;quot;app.port&amp;quot;))

println(&amp;quot;Hit any key to exit.&amp;quot;)
val result = readLine()
system.shutdown()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Because Spray is based on Akka, we are just creating a standard actor system and passing our service to &lt;a href=&#34;http://doc.akka.io/docs/akka/snapshot/scala/io.html&#34;&gt;Akka&amp;#8217;s new IO library&lt;/a&gt;. This is the high performance foundation for our service built on the spray-can server.&lt;/p&gt;

&lt;h2 id=&#34;the-service-actor:e4c25fe8ca10d79600b3f827b4d5c8dd&#34;&gt;The Service Actor&lt;/h2&gt;

&lt;p&gt;Our service actor is pretty lightweight, as the functionality is deferred to our route definition in the HttpService trait. We only need to set the actorRefFactory and call runRoutes from our trait. You could simply set routes directly in this class, but the separation has its benefits, primarily for testing.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!scala
class SpraySampleActor extends Actor with SpraySampleService with SprayActorLogging {
  def actorRefFactory = context
  def receive = runRoute(spraysampleRoute)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;the-service-trait-8211-spray-8217-s-routing-dsl:e4c25fe8ca10d79600b3f827b4d5c8dd&#34;&gt;The Service Trait &amp;#8211; Spray&amp;#8217;s Routing DSL&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://spray.io/documentation/1.1-M8/spray-routing/key-concepts/routes/&#34;&gt;Spray&amp;#8217;s Routing DSL&lt;/a&gt; is where Spray really shines. It is similar to Sinatra inspired web frameworks like Scalatra, but relies on composable function elements so requests pass through a series of actions similar to &lt;a href=&#34;http://unfiltered.databinder.net/&#34;&gt;Unfiltered&lt;/a&gt;. The result is an easy to read syntax for routing and the Dont-Repeat-Yourself of composable functions.&lt;/p&gt;

&lt;p&gt;To start things off, we&amp;#8217;ll create a simple get/post operation at the /entity path:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!scala
trait SpraySampleService extends HttpService {
  val spraysampleRoute = {
    path(&amp;quot;entity&amp;quot;) {
      get { 
        complete(&amp;quot;list&amp;quot;)
      } ~
      post {
        complete(&amp;quot;create&amp;quot;)
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The path, get and complete operations are &lt;a href=&#34;http://spray.io/documentation/1.1-M8/spray-routing/key-concepts/directives/#directives&#34;&gt;Directives&lt;/a&gt;, the building blocks of Spray routing. Directives take the current http request and process a particular action against it. The above snippet doesn&amp;#8217;t much except filter the request on the current path and the http action. The path directive also lets you pull out path elements:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!scala
path (&amp;quot;entity&amp;quot; / Segment) { id =&amp;gt;
    get {
      complete(s&amp;quot;detail ${id}&amp;quot;)
    } ~
    post {
      complete(s&amp;quot;update ${id}&amp;quot;)
    }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are a number ways to pull out elements from a path. Spray&amp;#8217;s unit tests are the best way to explore the possibilities.&lt;/p&gt;

&lt;p&gt;You can use curl to test the service so far:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!bash
curl -v http://localhost:8080/entity
curl -v http://localhost:8080/entity/1234
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;unmarshalling:e4c25fe8ca10d79600b3f827b4d5c8dd&#34;&gt;Unmarshalling&lt;/h2&gt;

&lt;p&gt;One of the nice things about Spray&amp;#8217;s DSL is how function composition allows you to build up request handling. In this snippet we use json4s support to unmarshall the http request into a JObject:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!scala
/* We need an implicit formatter to be mixed in to our trait */
object Json4sProtocol extends Json4sSupport {
  implicit def json4sFormats: Formats = DefaultFormats
}

trait SpraySampleService extends HttpService {
  import Json4sProtocol._

  val spraysampleRoute = {
    path(&amp;quot;entity&amp;quot;) {
      /* ... */
      post {
        entity(as[JObject]) { someObject =&amp;gt;
          doCreate(someObject)
        }
      } 
     /* ... */
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We use the Entity to directive to unmarshall the request, which finds the implicit json4s serializer we specified earlier. SomeObject is set to the JObject produced, which is passed to our yet-to-be-built doCreate method. If Spray can&amp;#8217;t unmarshall the entity an error is returned to the client.&lt;/p&gt;

&lt;p&gt;Here&amp;#8217;s a curl command that sets the http method to POST and applies the appropriate header and json body:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!bash
curl -v -X POST http://localhost:8080/entity -H &amp;quot;Content-Type: application/json&amp;quot; -d &amp;quot;{ \&amp;quot;property\&amp;quot; : \&amp;quot;value\&amp;quot; }&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;leveraging-akka-and-futures:e4c25fe8ca10d79600b3f827b4d5c8dd&#34;&gt;Leveraging Akka and Futures&lt;/h2&gt;

&lt;p&gt;We want to keep our route structure clean, so we defer actual work to another Akka worker. Because Spray is built with Akka this is pretty seamless. We need to create our ActorRef to send a message. We&amp;#8217;ll also implement our doCreate function called within the earlier POST /entity directive:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!scala
//Our worker Actor handles the work of the request.
val worker = actorRefFactory.actorOf(Props[WorkerActor], &amp;quot;worker&amp;quot;)

def doCreate[T](json: JObject) = {
  //all logic must be in the complete directive
  //otherwise it will be run only once on launch
  complete {
    //We use the Ask pattern to return
    //a future from our worker Actor,
    //which then gets passed to the complete
    //directive to finish the request.
    (worker ? Create(json))
                .mapTo[Ok]
                .map(result =&amp;gt; s&amp;quot;I got a response: ${result}&amp;quot;)
                .recover { case _ =&amp;gt; &amp;quot;error&amp;quot; }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There&amp;#8217;s a couple of things going on here. Our worker class is looking for a Create message, which we send to the actor with the ask (?) pattern. The ask pattern lets us know the task completed so we call then tell the client. When we get the Ok message we simply return the result; in the case of an error we return a short message. The response future returned is passed to Spray&amp;#8217;s complete directive, which will then complete the request to the client. There&amp;#8217;s no blocking occurring in this snippet: we are just wiring up futures and functions.&lt;/p&gt;

&lt;p&gt;Our worker doesn&amp;#8217;t do much but out the message contents and return a random number:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!scala
class WorkerActor extends Actor with ActorLogging {
import WorkerActor._

def receive = {
  case Create(json) =&amp;gt; {
    log.info(s&amp;quot;Create ${json}&amp;quot;)
    sender ! Ok(util.Random.nextInt(10000))
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can view how the entire request is handled &lt;a href=&#34;https://github.com/mhamrah/spray-sample/blob/master/src/main/scala/Boot.scala&#34;&gt;by viewing the source file&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;wrapping-up:e4c25fe8ca10d79600b3f827b4d5c8dd&#34;&gt;Wrapping Up&lt;/h2&gt;

&lt;p&gt;Reading the documentation and exploring the unit tests are the best way to understand the power of Spray&amp;#8217;s routing DSL. The performance of the standalone &lt;a href=&#34;http://spray.io/documentation/1.1-M8/spray-can/&#34;&gt;spray-can&lt;/a&gt; service is outstanding, and the Akka platform adds resiliency through its lifecycle management tools. Akka&amp;#8217;s remoting feature allows systems to build out their app tiers. A project I&amp;#8217;m working on is using Spray and Akka to publish messages to a pub/sub system for downstream request handling. It&amp;#8217;s an excellent platform for high performance API development. &lt;a href=&#34;https://github.com/mhamrah/spray-sample&#34;&gt;Full spray-sample is on GitHub&lt;/a&gt;.&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>How to Handle a Super Bowl Size Spike in Web Traffic</title>
          <link>http://blog.michaelhamrah.com/2013/02/how-to-handle-a-super-bowl-size-spike-in-web-traffic/</link>
          <pubDate>Wed, 06 Feb 2013 00:00:00 UTC</pubDate>
          <author>Michael Hamrah</author>
          <guid>http://blog.michaelhamrah.com/2013/02/how-to-handle-a-super-bowl-size-spike-in-web-traffic/</guid>
          <description>

&lt;p&gt;I was shocked to learn the number of &lt;a href=&#34;http://www.yottaa.com/blog/bid/265815/Coke-SodaStream-the-13-Websites-That-Crashed-During-Super-Bowl-2013&#34;&gt;sites which failed to handle the spike in web traffic during the Super Bowl&lt;/a&gt;. Most of these sites served static content and should have scaled easily with the use of CDNs. Scaling sites, even dynamic ones, are achievable with well known tools and techniques.&lt;/p&gt;

&lt;h2 id=&#34;the-problem-is-simple:9da68d5a6f235e570e3d7349e289ad5f&#34;&gt;The Problem is Simple&lt;/h2&gt;

&lt;p&gt;At a basic level accessing a web page is when one computer, the client, connects to a server and downloads some content. A problem occurs when the number of people requesting content exceeds the ability to deliver content. It&amp;#8217;s just like a restaurant. When there are too many customers people must wait to be served. Staff becomes stressed and strained. Computers are the same. Excessive load causes things to break down.&lt;/p&gt;

&lt;h2 id=&#34;optimization-comes-in-three-forms:9da68d5a6f235e570e3d7349e289ad5f&#34;&gt;Optimization Comes in Three Forms&lt;/h2&gt;

&lt;p&gt;To handle more requests there are three things you can do: produce (render) content faster, deliver (download) content faster and add more servers to handle more connections. Each of these solutions has a limit. Designing for these limits is architecting for scale.&lt;/p&gt;

&lt;p&gt;A page is composed of different types of content: html, css and js. This content is either dynamic (changes frequently) or static (changes infrequently). Static content is easier to scale because you create it once and deliver it repeatedly. The work of rendering is eliminated. Static content can be pushed out to CDNs or cached locally to avoid redownloading. Requests to origin servers are reduced or eliminated. You can also download content faster with small payload sizes. There is less to deliver if there is less markup and the content is compressed. Less to deliver means faster download.&lt;/p&gt;

&lt;p&gt;Dynamic content is trickier to cache because it is always changing. Reuse is difficult because pages must be regenerated for specific users at specific times. Scaling dynamic content involves database tuning, server side caching, and code optimization. If you can render a page quickly you can deliver more pages because the server can move on to new requests. Most often, at scale, you want to treat treat dynamic content like static content as best you can.&lt;/p&gt;

&lt;p&gt;Adding more servers is usually the easiest way to scale but breaks down quickly. The more servers you have the more you need to keep in sync and manage. You may be able to add more web servers, but those web servers must connect to database servers. Even powerful database servers can only handle so many connections and adding multiple database servers is complicated. You may be able to add specific types of servers, like cache servers, to achieve the results you need without increasing your entire topology.&lt;/p&gt;

&lt;p&gt;The more servers you have the harder it is to keep content fresh. You may feel increasing your servers will increase your load. It will become expensive to both manage and run. You may be able to achieve a similar result if you cut your response times which also gives the end user a better experience. If you understand the knobs and dials of your system you can tune properly.&lt;/p&gt;

&lt;h2 id=&#34;make-assumptions:9da68d5a6f235e570e3d7349e289ad5f&#34;&gt;Make Assumptions&lt;/h2&gt;

&lt;p&gt;Don&amp;#8217;t be afraid to make assumptions about your traffic patterns. This will help you optimize for your particular situation. For most publicly facing websites traffic is anonymous. This is particularly true during spikes like the Super Bowl. Because you can deliver the same page to every anonymous user you effectively have static content for those users. Cache controls determine how long content is valid and powers HTTP accelerators and CDNs for distribution. You don&amp;#8217;t need to optimize for everyone; split your user base into groups and optimize for the majority. Even laxing cache rules on pages to a minute can shift the burden away from your application servers freeing valuable resources. Anonymous users will get the benefit of cached content with a quick download, dynamic users will have fast servers.&lt;/p&gt;

&lt;p&gt;You can also create specific rendering pipelines for anonymous and known users for highly dynamic content. If you can identify anonymous users early you may be able to avoid costly database queries, external API calls or page renders.&lt;/p&gt;

&lt;h2 id=&#34;understand-http:9da68d5a6f235e570e3d7349e289ad5f&#34;&gt;Understand HTTP&lt;/h2&gt;

&lt;p&gt;HTTP powers the web. The better you understand HTTP the better you can leverage tools for optimizing the web. Specifically look at &lt;a href=&#34;http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html&#34;&gt;http cache headers&lt;/a&gt; which allow you to use web accelerators like Varnish and CDNs. The vary header will allow you to split anonymous and known users giving you fine grained control on who gets what. Expiration headers determine content freshness. The worst thing you can do is set cache headers to private on static content preventing browsers from caching locally.&lt;/p&gt;

&lt;h2 id=&#34;try-varnish-and-esi:9da68d5a6f235e570e3d7349e289ad5f&#34;&gt;Try Varnish and ESI&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.varnish-cache.org&#34;&gt;Varnish&lt;/a&gt; is an HTTP accelerator. It caches dynamic content produced from your website for efficient delivery. Web frameworks usually have their own features for caching content, but Varnish allows you to bypass your application stack completely for faster response times. You can deliver a pre-rendered dynamic page as if it were a static page sitting in memory for a greater number of connections.&lt;/p&gt;

&lt;p&gt;Edge Side Includes allow you to mix static and dynamic content together. If a page is 90% similar for everyone, you can cache the 90% in Varnish and have your application server deliver the other 10%. This greatly reduces the work your app server needs to do. ESI&amp;#8217;s are just emerging into web frameworks. It will play a more prominent role in Rails 4.&lt;/p&gt;

&lt;h2 id=&#34;use-a-cdn-and-multiple-data-centers:9da68d5a6f235e570e3d7349e289ad5f&#34;&gt;Use a CDN and Multiple Data Centers&lt;/h2&gt;

&lt;p&gt;You don&amp;#8217;t need to add more servers to your own data center. You can leverage the web to fan work out across the Internet. I talk more about CDN&amp;#8217;s, the importance of edge locations and latency in my post &lt;a href=&#34;http://www.michaelhamrah.com/blog/2012/01/building-for-the-web-understanding-the-network/&#34;&gt;Building for the Web: Understanding the Network&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Your application servers should be reserved for doing application-specific work which is unique to every request. There are more efficient ways of delivering the same content to multiple people than processing a request top-to-bottom via a web framework. Remember &amp;#8220;the same&amp;#8221; doesn&amp;#8217;t mean the same indefinitely; it&amp;#8217;s the same for whatever timeframe you specify.&lt;/p&gt;

&lt;p&gt;If you run Varnish servers in multiple data centers you can effectively create your own CDN. Your database and content may be on the east coast but if you run a Varnish server on the west coast an anonymous user in San Fransisco will have the benefit of a fast response time and you&amp;#8217;ve saved a connection to your app server. Even if Varnish has to deliver 10% dynamic content via an ESI on the east coast it can leverage the fast connection between data centers. This is much better then the end user hoping coast-to-coast themselves for an entire page.&lt;/p&gt;

&lt;p&gt;Amazon&amp;#8217;s Route 53 offers the ability to route requests to an optimal location. There are other geo-aware DNS solutions. If you have a multi-region setup you are not only building for resiliency your are horizontally scaling your requests across data centers. At massive scale even load balancers may become overloaded so round-robin via DNS becomes essential. DNS may be a bottleneck as well. If your DNS provider can&amp;#8217;t handle the flood of requests trying to map your URL to your IP address nobody can even get to your data center!&lt;/p&gt;

&lt;h2 id=&#34;use-auto-scaling-groups-or-alerting:9da68d5a6f235e570e3d7349e289ad5f&#34;&gt;Use Auto Scaling Groups or Alerting&lt;/h2&gt;

&lt;p&gt;If you can take an action when things get rough you can better handle spikes. Auto scaling groups are a great feature of AWS when some threshold is maxed. If you&amp;#8217;re not on AWS good monitoring tools will help you take action when things hit a danger zone. If you design your application with auto-scaling in mind, leveraging load balancers for internal communication and avoiding state, you are in a better position to deal with traffic growth. Scaling on demand saves money as you don&amp;#8217;t need to run all your servers all the time. Pinterest gave a talk explaining how it saves money by reducing its server farm at night when traffic is low.&lt;/p&gt;

&lt;h2 id=&#34;compress-and-serialized-data-across-the-wire:9da68d5a6f235e570e3d7349e289ad5f&#34;&gt;Compress and Serialized Data Across the Wire&lt;/h2&gt;

&lt;p&gt;Page sizes can be greatly reduced if you enable compression. Web traffic is mostly text which is easily compressible. A 100kb page is a lot faster to download than a 1mb page. Don&amp;#8217;t forget about internal communication as well. In todays API driven world using efficient serialization protocols like protocol buffers can greatly reduce network traffic. Most RPC tools support some form of optimal serialization. SOAP was the rage in the early 2000s but XML is one of the worst ways to serialize data for speed. Compressed content allows you to store more in cache and reduces network I/O as well.&lt;/p&gt;

&lt;h2 id=&#34;shut-down-features:9da68d5a6f235e570e3d7349e289ad5f&#34;&gt;Shut Down Features&lt;/h2&gt;

&lt;p&gt;A performance bottleneck may be caused by one particular feature. When developing new features, especially on a high traffic site, the ability to shut down a misbehaving feature could be the quick solution to a bad problem. Most high-traffic websites &amp;#8220;leak&amp;#8221; new features by deploying them to only 10% of their users to monitor behavior. Once everything is okay they activate the feature everywhere. Similar to determining page freshness for caches, determining available features under load can keep a site alive. What&amp;#8217;s more important: one specific feature or the entire system?&lt;/p&gt;

&lt;h2 id=&#34;non-blocking-i-o:9da68d5a6f235e570e3d7349e289ad5f&#34;&gt;Non-Blocking I/O&lt;/h2&gt;

&lt;p&gt;Asynchronous programming is a challenge and probably a last-resort for scaling. Sometimes servers break down without any visible threshold. You may have seen a slow request but memory, cpu, and network levels are all okay. This scenario is usually caused by blocking threads waiting on some form of I/O. Blocked threads are plugs that clog your application. They do nothing and prevent other things from happening. If you call external web services, run long database queries or perform disk I/O beware of synchronous operations. They are bottlenecks. Asynchronous based frameworks like node.js put asynchronous programming at the forefront of development making them attractive for handling numerous concurrent connections. Asynchronous programming also paves the way for queue-based architectures. If every request is routed through a queue and processed by a worker the queue will help even out spikes in traffic. The queue size will also determine how many workers you need. It may be trickier to code but it&amp;#8217;s how things scale.&lt;/p&gt;

&lt;h2 id=&#34;think-at-scale:9da68d5a6f235e570e3d7349e289ad5f&#34;&gt;Think at Scale&lt;/h2&gt;

&lt;p&gt;When dealing with a high-load environment nothing can be off the table. What works for a few thousand users will grow out of control for a few million. Even small issues will become exponentially problematic.&lt;/p&gt;

&lt;p&gt;Scaling isn&amp;#8217;t just about the tools to deal with load. It&amp;#8217;s about the decisions you make on how your application behaves. The most important thing is determining page freshness for users. The decisions for an up-to-the-second experience for every user are a lot different than an up-to-the-minute experience for anonymous users. When dealing with millions of concurrent requests one will involve a lot of engineering complexity and the other can be solved quickly.&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Building for the Web: Understanding The Network</title>
          <link>http://blog.michaelhamrah.com/2012/01/building-for-the-web-understanding-the-network/</link>
          <pubDate>Fri, 06 Jan 2012 00:00:00 UTC</pubDate>
          <author>Michael Hamrah</author>
          <guid>http://blog.michaelhamrah.com/2012/01/building-for-the-web-understanding-the-network/</guid>
          <description>

&lt;p&gt;My &lt;a href=&#34;http://wp.me/pnRto-aa&#34;&gt;first post on web technology&lt;/a&gt; talks about what we are trying to accomplish when building for the web. There are four ways we can break down the standard flow of &lt;em&gt;client action/server action/result&lt;/em&gt;: delivering, serving, rendering and developing. This post focuses on delivering content by understanding the network. Why use a &lt;a href=&#34;http://en.wikipedia.org/wiki/Content_delivery_network&#34;&gt;cdn&lt;/a&gt;? What&amp;#8217;s all the fuss about connections and compressed static assets? The network is often overlooked but understanding how it operates is essential for building high performing websites. A 50ms rendering time with a 50ms db query is meaningless if it takes three seconds to download a page.&lt;/p&gt;

&lt;h2 id=&#34;tcp-know-it:117df65302b8db2107451cddb1557896&#34;&gt;TCP: Know It.&lt;/h2&gt;

&lt;p&gt;Going from client to server and back again rests on the network and how well you use it. &lt;a href=&#34;http://en.wikipedia.org/wiki/Transmission_Control_Protocol&#34;&gt;TCP&lt;/a&gt; dominates communication on the web and is worth knowing well. In order to send data from one point to another a connection is established between two points via a back-and-forth handshake. Once established, data flows between the two in a series of packets. TCP offers reliability by acknowledging receipt of every packet sent by sending a second acknowledgement packet back to the server. The time it takes to go from one end to another and back is called latency or round-trip time. At any given time there are packets in flight waiting acknowledgement of receipt. TCP only allows a certain amount of unacknowledged packets in flight; this is called window size. Connections start with small window sizes but as more successful transfers occur the window size will increase (&lt;a href=&#34;http://en.wikipedia.org/wiki/Slow-start&#34;&gt;known as slow start&lt;/a&gt;). This effectively increases bandwidth because more data is sent at once. The longer the latency the slower a connection; if the window size is full then the server must wait for acknowledgements before sending more data. This is on top of the time it actually takes to send packets. The best case scenario is low latency with large, full windows.&lt;/p&gt;

&lt;h2 id=&#34;reliability:117df65302b8db2107451cddb1557896&#34;&gt;Reliability&lt;/h2&gt;

&lt;p&gt;Reliable connections are also important; if packets are lost they must be resent. Retransmissions slow down transfers because tcp guarantees in-order delivery of data to the application layer. If a packet is dropped and needs to be resent nothing will be delivered to the application until that one packet is received. UDP, an alternative to TCP, doesn&amp;#8217;t offer the same guarantees and assumes issues are dealt with at the application layer.&lt;/p&gt;

&lt;p&gt;There is a &lt;a href=&#34;http://coding.smashingmagazine.com/2011/11/14/analyzing-network-characteristics-using-javascript-and-the-dom-part-1/&#34;&gt;good article by Phillip Tellis on understanding the network with JS&lt;/a&gt; which talks about data transfer and TCP. &lt;a href=&#34;http://www.wireshark.org/&#34;&gt;Wireshark&lt;/a&gt; is another great tool for analyzing packets across a network. You can actually view individual packets as they come and go and see how window size is scaling, view retransmissions, measure bandwidth, and examine latency.&lt;/p&gt;

&lt;h2 id=&#34;the-importance-of-connections:117df65302b8db2107451cddb1557896&#34;&gt;The Importance of Connections&lt;/h2&gt;

&lt;p&gt;Establishing a connection takes time because of the handshake involved and latency considerations. A 100ms latency could mean more than 300ms before any data is even received on top of dealing with any dns lookups and os overhead. Keeping a connection alive avoids this creation overhead. Connection pooling, for example, is a popular technique to manage database connections. A web server will talk to a database frequently; if the connection is already established there is no overhead in executing a new query which can trim valuable time off of serving a request. &lt;a href=&#34;http://en.wikipedia.org/wiki/Ping&#34;&gt;Ping&lt;/a&gt; and &lt;a href=&#34;http://en.wikipedia.org/wiki/Traceroute&#34;&gt;traceroute&lt;/a&gt; are two worthwhile tools that examine latency and the &amp;#8220;hops&amp;#8221; packets take from one network to another as they travel from end to end.&lt;/p&gt;

&lt;p&gt;Connections take time to create, have a relatively limited availability and require overhead to manage. It may seem like a great idea to keep connections open for the long haul, but there is a limited number of connections a server can sustain. Concurrent connections is a popular benchmark which examines how many simultaneous connections can occur at any given time. If you hit that mark, new requests will have to wait until something frees up. The ideal situation is to pump as much as possible through a few connections so there are more available to others. If you can serve multiple files files at once great; but why keep six empty connections open between requests if you don&amp;#8217;t need too?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;On a side note, this is where server architecture comes into play. A server usually processes a request by building a web page from a framework. If this can be done asynchronously by the web server, or offloaded somewhere else, the web server can handle a higher number of sustained connections. The server can grab a new connection while it waits for data to send on an existing one. We&amp;#8217;ll talk more about this in another post. Fast server times also keep high concurrent connections from arising in the first place.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;optimizing-the-network:117df65302b8db2107451cddb1557896&#34;&gt;Optimizing the Network&lt;/h2&gt;

&lt;p&gt;Lowering latency and optimizing data throughput are what dominate delivery optimization. It is important to keep the data which flows between client and server to a minimum. Downloading a 100kb page is a lot faster than downloading a 1000kb page. Compressing static content like css and javascript greatly reduces payload which is why tools like &lt;a href=&#34;http://documentcloud.github.com/jammit/&#34;&gt;Jammit&lt;/a&gt; and &lt;a href=&#34;http://code.google.com/closure/&#34;&gt;Google Closure&lt;/a&gt; are so ubiquitous. These tools can also merge files; because of http chatter it is faster to download one larger file than several small files. Remember the importance of knowing http? Each http request requires reusing or establishing a connection, a header request sent, the server handling the request, and the response. Doing this once is better than twice. Most web servers can also dynamically compress http responses and should be used when possible.&lt;/p&gt;

&lt;p&gt;Fixing latency can be done by using a content delivery network like &lt;a href=&#34;http://aws.amazon.com/cloudfront/&#34;&gt;Amazon Cloudfront&lt;/a&gt; or &lt;a href=&#34;http://www.akamai.com&#34;&gt;Akamai&lt;/a&gt;. They shorten the distance between a request and response by taking content from your server and spreading it on their infrastructure all over the world. When a user requests a resource the cdn routes the request to the server with the lowest latency. A user in Japan can download a file from Japan a lot faster than he can from Europe. Shorter distance, fewer hops, fewer retransmissions. A good cdn strategy rests on how easy it is to push content to a cdn and how easy it is to refresh it. Both concerns should be well researched when leveraging a cdn. You don&amp;#8217;t want stale css files in the wild when you release a new version of your app.&lt;/p&gt;

&lt;p&gt;A &lt;a href=&#34;http://en.wikipedia.org/wiki/WAN_optimization&#34;&gt;WAN accelerator&lt;/a&gt; is also a cool technique. Let&amp;#8217;s say you want to deliver a dynamic web page from the US to Tokyo. You could have that travel over the open internet with a high latency connection. Or you could route that request to a data center in Tokyo with an optimized connection to the US. The user gets a low-latency connection to the Tokyo datacenter which in turn gets a low-latency high bandwidth connection to the US. This can greatly simplify issues with running and keeping multiple data centers in sync.&lt;/p&gt;

&lt;h2 id=&#34;the-bottom-line:117df65302b8db2107451cddb1557896&#34;&gt;The Bottom Line&lt;/h2&gt;

&lt;p&gt;There&amp;#8217;s a lot of effort underway in making the web faster by changing how tcp connections are leveraged on the web. Http 1.0 requires a new connection for every request/response and browsers limit the number of parallel connections between client and server between two and six. Http keep-alive and &lt;a href=&#34;http://en.wikipedia.org/wiki/HTTP_pipelining&#34;&gt;http pipelining&lt;/a&gt; offer mechanisms to push more content through existing connections. Rails 3.1 introduced http streaming via chunked responses. Browsers can fetch assets in parallel with the main html response as soon as tags appear in the main response stream. &lt;a href=&#34;http://www.chromium.org/spdy/spdy-whitepaper&#34;&gt;Spdy&lt;/a&gt;, an effort by Google, is worth checking out: it proposes a multi-pronged attack to leverage as much flow as possible on a single connection. The docs also illustrate interesting pain points with the network on the web. The bottom line is simple: reduce the amount of data that needs to go from one place to another and make the travel time as fast as possible. Small amounts of data over existing parallel connections make a fast web.&lt;/p&gt;

&lt;p&gt;This approach shouldn&amp;#8217;t be limited to users and servers; optimizing network communication within your datacenter is extremely important. You have total control over your infrastructure and can tune your network accordingly. You can also choose your communication protocols: using something like &lt;a href=&#34;http://thrift.apache.org/&#34;&gt;thrift&lt;/a&gt; or &lt;a href=&#34;http://code.google.com/p/protobuf/&#34;&gt;protocol buffers&lt;/a&gt; can save a tremendous amount of bandwidth over xml-based web services on http.&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;:&lt;a href=&#34;http://www.scala-lang.org/&#34;&gt;http://www.scala-lang.org/&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;:&lt;a href=&#34;http://python.org/&#34;&gt;http://python.org/&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Building for the Web: What Are We Trying to Accomplish?</title>
          <link>http://blog.michaelhamrah.com/2012/01/web-technology-what-are-we-trying-to-accomplish/</link>
          <pubDate>Wed, 04 Jan 2012 00:00:00 UTC</pubDate>
          <author>Michael Hamrah</author>
          <guid>http://blog.michaelhamrah.com/2012/01/web-technology-what-are-we-trying-to-accomplish/</guid>
          <description>

&lt;p&gt;The web technology landscape is huge and growing every day. There are hundreds of options from servers to languages to frameworks for building the next big thing. Is it &lt;a href=&#34;http://www.nginx.org/en/&#34;&gt;nginx&lt;/a&gt; + &lt;a href=&#34;http://unicorn.bogomips.org/&#34;&gt;unicorn&lt;/a&gt; + &lt;a href=&#34;http://rubini.us/&#34;&gt;rubinus&lt;/a&gt; or a &lt;a href=&#34;http://nodejs.org/&#34;&gt;node.js&lt;/a&gt; restful service on &lt;a href=&#34;http://cassandra.apache.org/&#34;&gt;cassandra&lt;/a&gt; running with &lt;a href=&#34;http://emberjs.com/&#34;&gt;ember.js&lt;/a&gt; and html5 on the front end? Should I learn or ? What&amp;#8217;s the best nosql database for a socially powered group buying predicative analysis real-time boutique mobile aggregator that scales to 100 million users and never fails?&lt;/p&gt;

&lt;p&gt;It is true there are many choices out there but web technology boils down to a very simple premise. You want to respond to a user action as quickly as possible, under any circumstance, while easily changing functionality. Everything from the technology behind this blog to what goes into facebook operates on that simple idea. The problem comes down to doing it at the scale and speed of the modern web. You have hundreds of thousands of users; you have hundreds of thousands of things you want them to see; you want them to buy, share, create, and/or change those things; you want to deliver a beautiful, customized experience; everything that happens needs to be instantaneous; it can never stop working; and the cherry on the cake is that everything is constantly changing; different features, different experiences, different content; different users. The simple &amp;#8220;hello world&amp;#8221; app is easy. But how do you automatically translate that into every language with a personal message and show a real-time graph with historical data of every user accessing the page &lt;em&gt;at scale&lt;/em&gt;? What if we wanted to have users leave messages on the same page? Hopefully by the end of this series you will get a sense of how all the pieces fit together and what&amp;#8217;s involved from going to 10 users to 10 thousand to 10 million.&lt;/p&gt;

&lt;h2 id=&#34;the-web-at-50-000-feet:ba587cddf41afc4433f829b6dc01b418&#34;&gt;The Web at 50,000 Feet&lt;/h2&gt;

&lt;p&gt;The web breaks down to three distinct areas: what happens with the client, what happens on the server, and what happens in between. Usually this is rendering a web page: a user clicks a link, a page delivered, the browser displays the content. It could also involve handling an ajax request, calling an API, posting a search form. Either way it boils down to &lt;em&gt;client action, server action, result&lt;/em&gt;. Doing this within a users attention span given any amount of meaningful content in a fail-safe way with even the smallest amount of variation is why we have all this technology. It all works together to combine flexibility and speed with power and simplicity. The trick is using the right tool in the swiss-army knife of tech to get the job done.&lt;/p&gt;

&lt;p&gt;Let&amp;#8217;s break all this down a bit. Handling a user action well comes down to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Having the server-side handle the request quickly (Serving)&lt;/li&gt;
&lt;li&gt;A quick travel time between the client and server (Delivering)&lt;/li&gt;
&lt;li&gt;Quickly displaying the result (Rendering)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And developing and managing all this successfully comes down to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Changing any aspect of what is going on quickly and easily (Developing)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As sites grow and come under heavier load doing any one of these things becomes increasingly difficult. More features, more users, more servers, more code. There is only so much one server can do. There is also only so much a server &lt;em&gt;needs&lt;/em&gt; to do. Why hit the database if you can cache the result? Why render a page if you don&amp;#8217;t need to? Why download a one meg html page when it&amp;#8217;s only 100kb compressed? Why download a page if you don&amp;#8217;t have to? How do you do all this and keep your code simple? How do you ensure everything still works even if your &lt;a href=&#34;http://aws.amazon.com/message/65648/&#34;&gt;data center goes down&lt;/a&gt;?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Http plays an important role in all of this. I didn&amp;#8217;t truly appreciate http until I read &lt;a href=&#34;http://www.amazon.com/Restful-Web-Services-Leonard-Richardson/dp/0596529260&#34;&gt;Restful Web Services&lt;/a&gt; by Sam Ruby and Leonard Richardson. Http as an application protocol offers an elegant, scalable mechanism for transferring data and defining intent. Understanding http verbs, various http headers and how http sits on top of tcp/ip can go along way in mastering the web.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;making-it-all-work-together:ba587cddf41afc4433f829b6dc01b418&#34;&gt;Making it all work together&lt;/h2&gt;

&lt;p&gt;So how do you choose and use all the tools out there to serve, deliver, render and develop for the web? What does &lt;em&gt;client action/server action/result&lt;/em&gt; have to do with &lt;a href=&#34;http://rack.rubyforge.org/&#34;&gt;rack&lt;/a&gt; and &lt;a href=&#34;http://en.wikipedia.org/wiki/Web_Server_Gateway_Interface&#34;&gt;wsgi&lt;/a&gt;? I navely thought I could write everything I wanted to in a single post: from using &lt;a href=&#34;http://sass-lang.com/&#34;&gt;sass&lt;/a&gt; for compressed, minimized css to sharding databases for horizontal scalability. It will be easier to spread it out a bit so stay tuned. But remember: any language, framework or tool out there is really about improving &lt;em&gt;client action/server action/result&lt;/em&gt;. Even something like &lt;a href=&#34;http://en.wikipedia.org/wiki/WebSocket&#34;&gt;websockets&lt;/a&gt;. Websockets eliminates the client request completely. Why wait for a user to tell you something when you can push them content? Knowing your problem domain, your bottlenecks, and your available options will help you choose the right tool and make the right time/cost/benefit decision.&lt;/p&gt;

&lt;p&gt;I&amp;#8217;ll dig into the constraints and various techniques to effectively &lt;a href=&#34;http://wp.me/pnRto-af&#34;&gt;deliver&lt;/a&gt;, &lt;a href=&#34;http://wp.me/pnRto-al&#34;&gt;serve, develop&lt;/a&gt; and &lt;a href=&#34;http://wp.me/pnRto-at&#34;&gt;render&lt;/a&gt; for the web in upcoming posts.&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Nina, My New Favorite Web (Micro)Framework</title>
          <link>http://blog.michaelhamrah.com/2011/05/nina-my-new-favorite-web-microframework/</link>
          <pubDate>Tue, 10 May 2011 00:00:00 UTC</pubDate>
          <author>Michael Hamrah</author>
          <guid>http://blog.michaelhamrah.com/2011/05/nina-my-new-favorite-web-microframework/</guid>
          <description>

&lt;p&gt;One of the things I&amp;#8217;m excited to see is the huge increase in Open Source projects in the .NET world. NuGet has certainly helped the recent explosion, but even before that there have been numerous projects gaining legs in the .NET community. Even better, the movement has been learning from other programming ecosystems to bring some great functionality into all kinds of .NET based systems.&lt;/p&gt;

&lt;p&gt;One of my favorite projects on the scene is &lt;a href=&#34;http://jondot.github.com/nina/&#34;&gt;Nina, a Web Micro Framework&lt;/a&gt; by &lt;a href=&#34;http://twitter.com/#!/jondot&#34;&gt;jondot&lt;/a&gt;. What exactly is a web micro framework? Quite simply it easily allows you to go from an HTTP request to a server side method call with little friction. The project is inspired by &lt;a href=&#34;http://www.sinatrarb.com/&#34;&gt;Sinatra&lt;/a&gt; a very popular ruby framework for server-side interaction which doesn&amp;#8217;t involve all the overhead of a convention based framework like Ruby on Rails.&lt;/p&gt;

&lt;h2 id=&#34;wait-isn-8217-t-this-mvc:340cb49b2e29e9bef84588c65c69d675&#34;&gt;Wait, Isn&amp;#8217;t This .MVC?&lt;/h2&gt;

&lt;p&gt;Sort of- but the two frameworks take very different approaches in how they map an HTTP request to a function call. .MVC is a huge improvement over &amp;#8220;that which must not be named&amp;#8221; but still abstracts the underlying HTTP request/response: controllers and actions to handle logic, models to represent data, views to render results, and routing to figure out what to do. This is usually a good thing as you can easily get fully formed objects into and out of the server in an organized way and has incredible benefits over WebForms. But sometimes that is too much for what you want or need. In our ajax driven world we simply want to do something&amp;#8211;GET or POST some data&amp;#8211;as quickly and easily as possible. We don&amp;#8217;t want to set up a routing for new controller, create a model or view model, invoke an action, return a view, and all that other stuff; we just want to look at the request and do something. That&amp;#8217;s where Nina comes in- it elegantly lets you &amp;#8220;think&amp;#8221; in HTTP by providing an API to do something based on a given HTTP request. It&amp;#8217;s extremely lightweight and extremely fast. It&amp;#8217;s the bare essentials of MVC by providing a minimalist view of functionality in a well defined DSL. On the plus side, the MVC framework and Nina can complement each other quite well (Nina can also stand on its own, too!). Let&amp;#8217;s take a look.&lt;/p&gt;

&lt;h2 id=&#34;how-it-works:340cb49b2e29e9bef84588c65c69d675&#34;&gt;How It Works&lt;/h2&gt;

&lt;p&gt;Nina is essentially functionality added to a web project in the same way the MVC bits are added to a web project. It&amp;#8217;s not an entirely new HTTP server implementation. It&amp;#8217;s powered off of the standard .NET HttpApplication class and unlike the various &lt;a href=&#34;http://owin.org/&#34;&gt;OWIN&lt;/a&gt; toolkits Nina doesn&amp;#8217;t try and rewrite the underlying HttpContext or IIS server stack. To start things off Nina is powered by creating a class that handles all requests to a given url, referred to as an endpoint. This class inherits from &lt;em&gt;Nina.Application&lt;/em&gt; and handles all requests to that endpoint- no matter what the rest of the url is. This is done by &amp;#8220;mounting&amp;#8221; the class to an endpoint in your Global.asax file. It&amp;#8217;s not too different than setting up a routing for MVC. However, instead of MVC, you&amp;#8217;re not routing directly to specific actions or a pattern of actions, but &amp;#8220;gobbing&amp;#8221; up all requests to that url endpoint. Below is an example of a global.asax file from the Nina demo project. There are two Nina applications- the Contacts class gets mounted to the contacts endpoint and Posts gets mounted to the blog endpoint.&lt;/p&gt;

&lt;pre class=&#34;syntax c#&#34;&gt;private static void RegisterRoutes()
    {
            RouteTable.Routes.Add(new MountingPoint(&#34;contacts&#34;));
            RouteTable.Routes.Add(new MountingPoint(&#34;blog&#34;));
    }&lt;/pre&gt;

&lt;p&gt;When you&amp;#8217;re mounting an endpoint any request to that endpoint will go to that class- and that class will handle everything else. So anything with a url of /contacts, /contacts/123, /contacts/some/long/path/with/file.html?x=1&amp;amp;y=1 will go to the Contacts class. There&amp;#8217;s no automatic mapping of url parts to action names, or auto filling of parameters. That&amp;#8217;s all handled by the class you specify which inherits from Nina.Application. Routing to individual methods is handled within these classes by leveraging the Nina DSL. I like this approach, as it keeps routing logic tied to specific endpoints rather than requiring you to centrally locate everything or to dictate globally how routing should work via conventions. Of course, there are pros and cons in either case. In very complex systems the Global.asax can get quite large; you can certainly refactor routing logic into helper functions as necessary, but moving routing definitions closer to the logic has its benefits. I&amp;#8217;m also not too big of a fan when it comes to attribute based programming so not having to pepper your action methods with specific filters- whether for a Uri template in the case of WCF or Http Verbs for .MVC- is a big plus.&lt;/p&gt;

&lt;h2 id=&#34;handling-requests:340cb49b2e29e9bef84588c65c69d675&#34;&gt;Handling Requests&lt;/h2&gt;

&lt;p&gt;This is where the beauty of Nina comes in. Once we&amp;#8217;ve mounted an application to an endpoint we can handle what to do based on two variables: the HTTP method and the path of the request. This is done via four function calls which are part of the Nina.Application class and map to the four HTTP verbs: Get(), Put(), Post() and Delete(). Each function takes in two parameters: the first is a Uri template which determines when this method gets invoked. The second is a lambda with a signature of Func&lt;NameValueCollection, HttpContext, ResourceResult&gt;. This lambda is what gets invoked when the current requests matches the Uri template. The first parameter are the template parts (explained later), the second parameter is the underlying HttpContext object, and the Function returns a Nina.ResourceResult class. For all intents and purposes a ResourceResult is similar to an ActionResult in .MVC. Nina provides quite a number of ResourceResults, from Html views to various serialization objects to binary data.&lt;/p&gt;

&lt;p&gt;This setup is powered by an extremely nice DSL for handling function invocation from HTTP requests and yields a very nice description of your endpoint. You specify the HTTP verb required to invoke the function. You specify the Uri template to when that match should occur&amp;#8211;very similar to setting up routes&amp;#8211;and your handler is actually a parameter, which you can specify inline or elsewhere if needed. The Uri templating is pretty slick, as it allows any level of fuzzy matching. Because the template is automatically parsed and passed as a variable to your handler, you can easily get out elements of the Uri using the template tokens in your Uri. Let&amp;#8217;s take a look at a simple example:&lt;/p&gt;

&lt;p&gt;Take a look at the example application below.&lt;/p&gt;

&lt;pre class=&#34;syntax c#&#34;&gt;public class Contacts : Nina.Application
    {
        public Contacts()
        {
            Get(&#34;&#34;, (m, c) =&amp;gt;
                        {
                            //Returns anything at the root endpoint, i.e. /contacts
                            var data = SomeRepository.GetAll();
                            return Json(data);
                        });
            Get(&#34;Detail/{id}&#34;, (m, c) =&amp;gt;
                                   {
                                       //Returns /contacts/detail/XYZ

                                       //m is the bound parameters in the template
                                       //this will be a collection with m[&#34;ID&#34;] returning XYZ
                                       var id = m[&#34;ID&#34;]; //returns XYZ

                                       var data = SomeRepository.GetDetail(id);
                                       return View(&#34;viewname&#34;, data); //Nina has configurable ViewEngines!
                                   });

            Post(&#34;&#34;, (m,c) =&amp;gt;
                         {
                             //A post request to the root endpoint.

                             return Nothing(); 
                         });
         }
}&lt;/pre&gt;

&lt;p&gt;We&amp;#8217;re exposing three operations: two GET calls and one POST. We&amp;#8217;re handling a GET and POST operation at the endpoint root. In our global.asax we&amp;#8217;ve mounted this application at /contacts, so everything here is relative to /contacts. A template of &amp;#8220;&amp;#8221; will simply match a Uri of /contacts. If we wrote  &lt;code class=&#34;syntax c#&#34;&gt;RouteTable.Routes.Add(new MountingPoint(&amp;ldquo;contacts&amp;rdquo;));&lt;/code&gt; in our Global.asax than this class would be at the root of our application, i.e. &amp;#8220;&lt;a href=&#34;http://localhost/&amp;amp;#8221&#34;&gt;http://localhost/&amp;amp;#8221&lt;/a&gt;;. Finally, we have another GET call at /detail/{id}. This is actually a URI template, similar to a Route, so anything which matches that template will be handled by that function. In this case /detail/123 or /detail/xyz would match. The template variables are passed as a key/value array in the &amp;#8220;m&amp;#8221; parameter of the lambda and can easily be pulled out. These are your template parts that are automatically parsed out for you.&lt;/p&gt;

&lt;p&gt;Using this DSL we can create any number of handlers for any GET, POST, PUT or even DELETE request. We can easily access HTTP Headers, Form variables, or the Request/Response objects from the HttpContext class. Most importantly we can easily view how a request will get handled by our system. The abstraction that MVC brings via Routes, Controllers and Actions is helpful; but not always necessary. Nina provides a different way of describing what you want done that serves a variety of purposes.&lt;/p&gt;

&lt;h2 id=&#34;returning-results:340cb49b2e29e9bef84588c65c69d675&#34;&gt;Returning Results&lt;/h2&gt;

&lt;p&gt;So far we&amp;#8217;ve focused on the Request side of Nina and haven&amp;#8217;t delved too much in the Response side. Nina&amp;#8217;s response system is very similar to .MVC&amp;#8217;s ActionResult infrastructure. Nina has a suite of classes which inherit from ResourceResult that allows you to output a response in a variety of ways. You can serialize an object into Json or Xml, render straight text, return a file, return only a status code, or even return a view. Nina supports numerous View engines&amp;#8211;including Razor but also NHaml, NDjango and Spark&amp;#8211;that&amp;#8217;s beyond the scope of this blog but worth checking out. I&amp;#8217;m a big fan of Haml. Results are returned using one of the method calls provided through the Nina.Application class and should serve all your needs. The best thing to do is explore the Nina.Application class itself and find out which methods return ResourceResults objects.&lt;/p&gt;

&lt;h2 id=&#34;this-is-cool-but-why-use-it:340cb49b2e29e9bef84588c65c69d675&#34;&gt;This is cool, but why use it?&lt;/h2&gt;

&lt;p&gt;The great part about Nina is that even though it can stand alone as an application, it can just as easily augment an existing WebForms (Blah!) or MVC application via mounting endpoints using the Routing engine. There are times when you want speed and simplicity for your web app rather than a fully-fledged framework. MVC is great, but requires quite a few moving parts and abstracts away underlying HTTP. The new Restful Web API&amp;#8217;s Microsoft is rolling out for WCF are also nice, but I&amp;#8217;ve never been a fan of attribute based programming and the WCF endpoints are service specific. Nina offers much more flexibility. Nina strikes the right balance by honoring existing HTTP conventions while providing flexibility of output. Sinatra, Nina&amp;#8217;s inspiration, came about by those who didn&amp;#8217;t want to follow the Rails bandwagon and the MVC convention it implemented. They wanted an easier, lightweight way of parsing and handling HTTP requests, and that&amp;#8217;s exactly what Nina does.&lt;/p&gt;

&lt;p&gt;Here are some use cases where Nina works well:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Json powered services. Even though MVC has JsonResult, Nina provides a low friction way of issuing a get request to return Json data, useful for Autosuggest lists or other Json powered services. JQuery thinks in terms of get/post commands so mapping these directly to mounted endpoints becomes much more fluid. One of my more popular articles is the &lt;a href=&#34;http://www.michaelhamrah.com/blog/2010/08/the-new-webapp-architecture-asp-net-mvc-3-jquery-templating-with-pure-and-the-json-value-provider/&#34;&gt;New Web App Architecture&lt;/a&gt;. Nina provides a nice alternative to Json powered services that can augment one of the newer javascript frameworks like &lt;a href=&#34;knockoutjs.com&#34;&gt;Knockout&lt;/a&gt; or &lt;a href=&#34;http://documentcloud.github.com/backbone/&#34;&gt;Backbone&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Better file delivery. HttpHandlers work well, but exist entirely outside the domain of your app. Powering file delivery through Nina- either because the info is in a data store or required specific authentication, works well.&lt;/li&gt;
&lt;li&gt;Conventions aren&amp;#8217;t required. Setting up routings, organizing views, and implementing action methods all require work and coding. Most of the time, you just want to render something or save something. Posting a search form, save a record via ajax, polling for alerts are all things that could be done with the conventions of MVC but aren&amp;#8217;t necessarily needed. Try the lightweight approach of Nina and you&amp;#8217;ll be glad you did. With support for View engines you may even want to come up with your own conventions for organizing content.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When the time it takes to do something simple simply becomes too great you&amp;#8217;re using the wrong tool. I strongly encourage you to play around with Nina&amp;#8211; you&amp;#8217;ll soon learn to love the raw power of HTTP and the simplicity of the API. It will augment your existing tool belt quite well and you&amp;#8217;ll find how much you can do when when you can express yourself in different ways.&lt;/p&gt;
</description>
        </item>
      
    

  </channel>
</rss>
