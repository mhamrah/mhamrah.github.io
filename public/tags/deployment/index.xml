<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> </title>
    <link>http://blog.michaelhamrah.com/tags/deployment/</link>
    <language>en-us</language>
    <author>Michael Hamrah</author>
    <rights>(C) 2015</rights>
    <updated>2015-03-25 00:00:00 &#43;0000 UTC</updated>

    
      
        <item>
          <title>Managing CoreOS Clusters on AWS with CloudFormation</title>
          <link>http://blog.michaelhamrah.com/2015/03/managing-coreos-clusters-on-aws-with-cloudformation/</link>
          <pubDate>Wed, 25 Mar 2015 00:00:00 UTC</pubDate>
          <author>Michael Hamrah</author>
          <guid>http://blog.michaelhamrah.com/2015/03/managing-coreos-clusters-on-aws-with-cloudformation/</guid>
          <description>&lt;p&gt;Personally, I find CloudFormation a somewhat annoying tool, yet I haven&amp;#8217;t replaced it with anything else. Those json files can get so ugly and unwieldy. Alternatives exist; you can try an abstraction like &lt;a href=&#34;https://github.com/cloudtools/troposphere&#34;&gt;troposphere&lt;/a&gt; or &lt;a href=&#34;https://jclouds.apache.org&#34;&gt;jclouds&lt;/a&gt;, or ditch cfn completely with something like &lt;a href=&#34;https://www.terraform.io&#34;&gt;terraform&lt;/a&gt;. These are interesting tools but somehow I find myself sticking with the straight-up json approach, the aws cli, and some bash scripting: the pieces are already there, they just need to be strung together. In the end it&amp;#8217;s not that bad, and there are some tools and techniques I&amp;#8217;ve picked up which really help out. I recently applied these to managing CoreOS clusters with CFN, and wanted to share a simplified version of the approach.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://coreos.com/docs/running-coreos/cloud-providers/ec2/&#34;&gt;CoreOS provides a default CloudFormation template&lt;/a&gt; which is a great start for cluster experimentation. But scaling out, where nodes are coming and going, can be disastrous for etcd&amp;#8217;s quorum consensus if you&amp;#8217;re not careful. You just don&amp;#8217;t want to remove nodes from a formed etcd cluster. &lt;a href=&#34;https://coreos.com/docs/cluster-management/setup/cluster-architectures/&#34;&gt;CoreOS&amp;#8217;s cluster documentation&lt;/a&gt; has a section on production configuration: you want a core set of nodes for running central services, with various worker nodes for specific purposes. We can elaborate this with a short-list of requirements:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;You want to tag sets of instances with specific roles so you can group dependencies and isolate apps when needed.&lt;/strong&gt;&lt;/em&gt; Although possible, it&amp;#8217;s unrealistic to actually run any app on any node. More likely you want to group apps into front-facing and back-facing and treat those nodes differently. For instance, you could map the IP&amp;#8217;s of front-facing nodes to a Route53 endpoint.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;You want a cluster of heterogeneous instances for different workloads&lt;/strong&gt;&lt;/em&gt; Certain apps require certain characteristics. Even though you&amp;#8217;re running everything in docker containers, you still want to have c4&amp;#8217;s for compute-intensive loads, r3&amp;#8217;s for memory-intensive loads, etc. Look at your applications and map them to a system topology. You can also scale these groups of instances differently, but you want to see your entire system as a whole: not as independent, discrete parts.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;At some point, you&amp;#8217;ll need to update the configuration of your instances. You want to do this surgically, without accidentally destroying your cluster&lt;/strong&gt;&lt;/em&gt;. You may be one bad cfn update from relaunching an auto scaling group or misconfiguring an instance which causes a replacement. Just like normal instances you want to apply updates and reconfiguration of nodes in a sane, logical way. If you only had one cfn template for your entire cluster, it&amp;#8217;s all or nothing. That&amp;#8217;s not a choice we want to make.&lt;/p&gt;

&lt;p&gt;CoreOS won&amp;#8217;t let you forget about the underlying nodes; it just adds a little abstraction so you don&amp;#8217;t need to deal with specific nodes as much.&lt;/p&gt;

&lt;p&gt;I&amp;#8217;m assuming you&amp;#8217;re familiar with CloudFormation and the basics of a template. For our setup we&amp;#8217;ll start with the &lt;a href=&#34;https://s3.amazonaws.com/coreos.com/dist/aws/coreos-stable-hvm.template&#34;&gt;us-east-1 hvm CoreOS template&lt;/a&gt; and modify it along the way. This template create a straight-up CoreOS cluster launched in an Auto Scaling Group, uses a LaunchConfig&amp;#8217;s UserData to set some Cloud-Config settings. Like most templates you need a few parameters to launch. The non-default ones are your keypair and the etcd Discovery Url for forming the cluster. We are going to launch this stack with the CLI (who needs user interfaces?)&lt;/p&gt;

&lt;p&gt;Let&amp;#8217;s create a bash script, &lt;code&gt;coreos-cfn.sh&lt;/code&gt;, to call our create stack (don&amp;#8217;t forget to chmod +x). We need a DiscoveryUrl so we&amp;#8217;ll get a new one in our script and pass it as a parameter to CFN.&lt;/p&gt;

&lt;pre class=&#34;syntax bash&#34;&gt;#!/bin/bash 

DISCOVERY_URL=`curl -s -w &#34;\n&#34; https://discovery.etcd.io/new`
#Check to make sure the above command worked, or exit
[[ $? -ne 0 ]] &amp;#038;&amp;#038; echo &#34;Could not generate discovery url.&#34; &amp;#038;&amp;#038; exit 1

if [ -z &#34;$COREOS_KEYPAIR&#34; ]; then
  KEYPAIR=yourkey.pem
fi

# Create the CloudFormation stack
aws cloudformation create-stack \
    --stack-name coreos-test \
    --template-body file://coreos-stable-hvm.template \
    --capabilities CAPABILITY_IAM \
    --tags Key=Name,Value=CoreOS \
    --parameters \
        ParameterKey=DiscoveryURL,ParameterValue=${DISCOVERY_URL} \
        ParameterKey=KeyPair,ParameterValue=${KEYPAIR}
&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;-z $KEYPAIR&lt;/code&gt; tests to see if there&amp;#8217;s a keypair set as an environment variable; if not, it uses the specified one. If you run &lt;code&gt;coreos-cfn.sh&lt;/code&gt; you should see the CLI spit out the ARN for the stack. Before we do that, let&amp;#8217;s make two minor tweaks.&lt;/p&gt;

&lt;p&gt;There are two key pieces of information we want to remember from this cluster: The DiscoveryUrl, so can access cluster state, and the AutoScalingGroup, so we can easily inspect instances in the future. Because the DiscoveryUrl is a parameter the aws cli will remember it for you. We need to add the auto scaling group as an output:&lt;/p&gt;

&lt;pre class=&#34;syntax json&#34;&gt;&#34;Outputs&#34;: {
    &#34;AutoScalingGroup&#34; : {
      &#34;Value&#34;: { &#34;Ref&#34;: &#34;CoreOSServerAutoScale&#34; }
    }
  }
&lt;/pre&gt;

&lt;p&gt;After launching the cluster we can use the CLI and some jq to get back these parameters. It&amp;#8217;s a simple built-in storage mechanism of AWS, and all you need is the original stack name:&lt;/p&gt;

&lt;pre class=&#34;syntax bash&#34;&gt;# Get back the DiscoveryURL: Describe the stack, select the parameter list
DISCOVERY_URL=`aws cloudformation describe-stacks --stack-name coreos-test | \
  jq -r &#39;[.Stacks[].Parameters[]][] | select (.ParameterKey == &#34;DiscoveryURL&#34;) | .ParameterValue&#39;`

# Get back the auto-scaling-group-id
LEADER_ASG=`aws cloudformation describe-stacks --stack-name coreos-test | \
  jq -r &#39;[.Stacks[].Outputs[]][] | select (.OutputKey == &#34;AutoScalingGroup&#34;) | .OutputValue&#39;`

echo &#34;Discovery Url is $DISCOVERY_URL and Leader ASG is $LEADER_ASG&#34;
&lt;/pre&gt;

&lt;p&gt;Why is this important? Because now we can either inspect the state of the cluster via the disovery url service, or query the ASG to inspect running nodes directly:&lt;/p&gt;

&lt;pre class=&#34;syntax bash&#34;&gt;# Query AWS for Leader Nodes
$aws ec2 describe-instances --filters Name=tag-value,Values=$LEADER_ASG | \
  jq &#39;.Reservations[].Instances[].NetworkInterfaces[].PrivateIpAddress&#39;

# Inspect the Discovery Url for nodes, trimming port. 
$ `curl -s $DISCOVERY_URL | jq &#39;.node.nodes[].value[0:-5]&#39;

# Taking the latter one step further, we can build an Etcd Peers string using Jq, xargs and tr
$ ETCD_PEERS=`curl -s $DISCOVERY_URL | jq &#39;.node.nodes[].value[0:-5]&#39; | xargs -I{}  echo &#34;{}:4001&#34; | tr &#34;\\n&#34; &#34;,&#34;`
# Drop the last ,
$ ETCD_PEERS=${ETCD_PEERS%?}
&lt;/pre&gt;

&lt;p&gt;Armed with this information we are now able to spin up new CoreOS nodes and have it use our CoreOS leader cluster for management. The &lt;a href=&#34;https://coreos.com/docs/cluster-management/setup/cluster-architectures/&#34;&gt;CoreOS Cluster Architecture page&lt;/a&gt; has the specific &lt;code&gt;cloud-config&lt;/code&gt; settings which amount to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Disable etcd, we don&amp;#8217;t need it&lt;/li&gt;
&lt;li&gt;Set etcd peer settings to a comma delimited list of nodes for Fleet, Locksmith&lt;/li&gt;
&lt;li&gt;Set environment variables for fleet and etcd in start scripts&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We&amp;#8217;ll make the etcd peer list a parameter for our template. We can duplicate our leader template, replace the &lt;code&gt;UserData&lt;/code&gt; portion of the &lt;code&gt;LaunchConfig&lt;/code&gt; with the updated settings from the link above, and add &lt;code&gt;{ Ref: }&lt;/code&gt; parameters where appropriate. Let&amp;#8217;s also add a metadata parameter as well:&lt;/p&gt;

&lt;pre class=&#34;syntax json&#34;&gt;&#34;Parameters&#34;: {
    &#34;EtcdPeers&#34; : {
      &#34;Description&#34; : &#34;A comma delimited list of etcd endpoints to use for state management.&#34;,
      &#34;Type&#34; : &#34;String&#34;
    },
    &#34;FleetMetadata&#34; : {
      &#34;Description&#34; : &#34;A comma delimited list of key=value attributes to apply for fleet&#34;,
      &#34;Type&#34; : &#34;String&#34;
    }
  }
&lt;/pre&gt;

&lt;p&gt;We can use the &lt;code&gt;Ref&lt;/code&gt; functionality to pass these to our &lt;code&gt;UserData&lt;/code&gt; script of the &lt;code&gt;LaunchConfig&lt;/code&gt;:&lt;/p&gt;

&lt;pre class=&#34;syntax json&#34;&gt;//other config above
  &#34;UserData&#34; : { &#34;Fn::Base64&#34;:
          { &#34;Fn::Join&#34;: [ &#34;&#34;, [
            &#34;#cloud-config\n\n&#34;,
            &#34;coreos:\n&#34;,
            &#34;  fleet:\n&#34;,
            &#34;    metadata: &#34;, { &#34;Ref&#34;: &#34;FleetMetadata&#34; }, &#34;\n&#34;,
            &#34;    etcd_servers: $&#34;, { &#34;Ref&#34;: &#34;EtcdPeers&#34; }, &#34;\n&#34;,
            &#34;  locksmith:\n&#34;,
            &#34;    endpoint: &#34;, { &#34;Ref&#34;: &#34;EtcdPeers&#34; }, &#34;\n&#34;
            ] ]
          }

// Other config below
&lt;/pre&gt;

&lt;p&gt;Finally we need a bash script which lets us inspect the existing stack information to pass as parameters to this new template. I also appreciate a CLI tool with a sane set of explicit flags. When I launch a secondary set of CoreOS nodes, I&amp;#8217;d like something simple to set the name, type, metadata and where I want to join to:&lt;/p&gt;

&lt;pre class=&#34;syntax bash&#34;&gt;$ launch-worker-group.sh -n r3-workers -t r3.large -j coreos-test -m &#34;instancetype=r3,role=worker&#34;
&lt;/pre&gt;

&lt;p&gt;Bash has a flag-parsing abilities in its &lt;code&gt;getopts&lt;/code&gt; function which we&amp;#8217;ll simply use to set variables:&lt;/p&gt;

&lt;pre class=&#34;syntax bash&#34;&gt;#!/bin/bash

while getopts n:j:m:s: FLAG; do
  case $FLAG in
    n)  STACK_NAME=${OPTARG};;
    j)  JOIN=${OPTARG};;
    m)  METADATA=${OPTARG};;
    t)  INSTANCE_TYPE =${OPTARG};;
    [?])
      print &gt;&amp;#038;2 &#34;Usage: $0 [ -n stack-name ] [ -j join to leader] [ -m fleet-metadata ] [ -t instance-type ]&#34;
      exit 1;;
  esac
done

shift $((OPTIND-1))

# You can set defaults, too:
if [ -z $INSTANCE_TYPE ]; then 
  INSTANCE_TYPE =&#34;m3.medium&#34;
fi
&lt;/pre&gt;

&lt;p&gt;With this in place it&amp;#8217;s just a matter of calling the AWS CLI with our new template and updated parameters. The only thing we&amp;#8217;re doing differently than the original script is using CloudFormation&amp;#8217;s json parameter functionality. This allows for more structured data in variables. Otherwise the comma-delimited list for etcd peers will throw off the CLI call.&lt;/p&gt;

&lt;pre class=&#34;syntax bash&#34;&gt;DISCOVERY_URL=`aws cloudformation describe-stacks --stack-name $JOIN | \
  jq -r &#39;[.Stacks[].Parameters[]][] | select (.ParameterKey == &#34;DiscoveryURL&#34;) | .ParameterValue&#39;`
# Taking the latter one step further, we can build an Etcd 
# Peers string using jq, xargs and tr to flatten
ETCD_PEERS=`curl -s $DISCOVERY_URL | jq &#39;.node.nodes[].value[0:-5]&#39; | \
  xargs -I{}  echo &#34;{}:4001&#34; | tr &#34;\\n&#34; &#34;,&#34;`

# Drop the last ,
ETCD_PEERS=${ETCD_PEERS%?}

 # Create the CloudFormation stack
 aws cloudformation create-stack \
    --stack-name STACK_NAME \
    --template-body file://coreos-worker-hvm.template \
    --capabilities CAPABILITY_IAM \
    --tags Key=Name,Value=CoreOS Key=Role,Value=Worker \
    --parameters &#34;[
      { \&#34;ParameterKey\&#34;:\&#34;FleetMetadata\&#34;,\&#34;ParameterValue\&#34;:\&#34;${METADATA}\&#34; },
      { \&#34;ParameterKey\&#34;:\&#34;InstanceType\&#34;,\&#34;ParameterValue\&#34;:\&#34;${INSTANCE_TYPE}\&#34; },
      { \&#34;ParameterKey\&#34;:\&#34;EtcdPeers\&#34;,\&#34;ParameterValue\&#34;:\&#34;${ETCD_PEERS%?}\&#34; },
      { \&#34;ParameterKey\&#34;:\&#34;KeyPair\&#34;,\&#34;ParameterValue\&#34;:\&#34;${KEYPAIR}\&#34; }
    ]&#34;
&lt;/pre&gt;

&lt;p&gt;And launch it! This will create a new stack for your worker nodes with whatever metadata you want, with whatever instance type you want.&lt;/p&gt;

&lt;p&gt;There are a few ways to extend this. For one, we haven&amp;#8217;t dealt with updating or destroying the stack. You can create separate shell scripts or combine them together with flags for determining which action to take. I prefer the latter as it keeps all related scripts in one file, but you can break out accordingly. You can use the AWS CLI and the Stack Name to query for private ip&amp;#8217;s and update Route 53 accordingly, bypassing the need for an ELB.&lt;/p&gt;

&lt;p&gt;You can do a lot with bash and other CLI tools like jq. You don&amp;#8217;t need to scour GitHub for open source tools, or frameworks that have bells and whistles. The core components are there, you just need to glue them together. Yes, your scripts may get out of hand, but at that point it&amp;#8217;s worth looking for alternatives because there&amp;#8217;s probably a specific problem you need to solve. Remember, be opinionated and let those choices guide you. At some point in the future I may be raving about Terraform; friends say it&amp;#8217;s a great tool, but it&amp;#8217;s just not one that I need-or particularly want-to use now.&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Using Typesafeâ€™s Config for Scala (and Java) for Application Configuration</title>
          <link>http://blog.michaelhamrah.com/2014/02/leveraging-typesafes-config-library-across-environments/</link>
          <pubDate>Sun, 23 Feb 2014 00:00:00 UTC</pubDate>
          <author>Michael Hamrah</author>
          <guid>http://blog.michaelhamrah.com/2014/02/leveraging-typesafes-config-library-across-environments/</guid>
          <description>

&lt;p&gt;I recently leveraged &lt;a href=&#34;https://github.com/typesafehub/config&#34;&gt;Typesafe&amp;#8217;s Config&lt;/a&gt; library to refactor configuration settings for a project. I was very pleased with the API and functionality of the library.&lt;/p&gt;

&lt;p&gt;The documentation is pretty solid so there&amp;#8217;s no need to go over basics. One feature I like is the clear hierarchy when specifying configuration values. I find it helpful to put as much as possible in a reference.conf file in the /resources directory for an application or library. These can get overridden in a variety of ways, primarily by adding an application.conf file to the bundled output&amp;#8217;s classpath. The &lt;a href=&#34;https://github.com/sbt/sbt-native-packager&#34;&gt;sbt native packager&lt;/a&gt;, helpful for deploying applications, makes it easy to attach a configuration file to an output. This is helpful if you have settings which you normally wouldn&amp;#8217;t want to use during development, say using remote actors with akka. I find placing a reasonable set of defaults in a reference.conf file allows you to easily transport a configuration around while still overriding it as necessary. Otherwise you can get into copy and paste hell by duplicating configurations across multiple files for multiple environments.&lt;/p&gt;

&lt;h2 id=&#34;alternative-overrides:25b0f7af66c88453ba07c790c20bec8d&#34;&gt;Alternative Overrides&lt;/h2&gt;

&lt;p&gt;There are two other interesting ways you can override configuration settings: using environment variables or java system properties. The environment variable approach comes in very handy when pushing to cloud environments where you don&amp;#8217;t know what a configuration is beforehand. Using the ${?VALUE} pattern a property will only be set if a value exists. This allows you to provide an option for overriding a value without actually having to specify one.&lt;/p&gt;

&lt;p&gt;Here&amp;#8217;s an example in a conf file using substitution leveraging this technique:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http {
 port = 8080
 port = ${?HTTP_PORT}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;#8217;re setting a default port of 8080. If the configuration can find a valid substitute it will replace the port value with the substitute; otherwise, it will keep it at 8080. The configuration library will look up its hierarchy for an HTTP_PORT value, checking other configuration files, Java system properties, and finally environment variables. Environment variables aren&amp;#8217;t perfect, but they&amp;#8217;re easy to set and leveraged in a lot of places. If you leave out the ? and just have ${HTTP_PORT} then the application will throw an exception if it can&amp;#8217;t find a value. But by using the ? you can override as many times as you want. This can be helpful when running apps on Heroku where environment variables are set for third party services.&lt;/p&gt;

&lt;h3 id=&#34;using-java-system-properties:25b0f7af66c88453ba07c790c20bec8d&#34;&gt;Using Java System Properties&lt;/h3&gt;

&lt;p&gt;Java system properties provide another option for setting config values. The shell script created by sbt-native-packager supports java system properties, so you can also set the http port via the command line using the -D flag:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bin/bash_script_from_native_packager -Dhttp.port=8081
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This can be helpful if you want to run an akka based application with a different log level to see what&amp;#8217;s going on in production:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bin/some_akka_app_script -Dakka.loglevel=debug
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Unfortunately sbt run doesn&amp;#8217;t support java system properties so you can&amp;#8217;t tweak settings with the command line when running sbt. The &lt;a href=&#34;https://github.com/spray/sbt-revolver&#34;&gt;sbt-revolver&lt;/a&gt; plugin, which allows you to run your app in a forked JVM, does allow you to pass java arguments using the command line. Once you&amp;#8217;re set up with this plugin you can change settings by adding your Java overrides after &lt;code&gt;---&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;re-start --- -Dhttp.port=8081
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;with-c3p0:25b0f7af66c88453ba07c790c20bec8d&#34;&gt;With c3p0&lt;/h3&gt;

&lt;p&gt;I was really excited to see that the &lt;a href=&#34;http://www.mchange.com/projects/c3p0/#c3p0_conf&#34;&gt;c3p0 connection pool library also supports Typesafe Config&lt;/a&gt;. So you can avoid those annoying xml-based files and merge your c3p0 settings directly with your regular configuration files. I&amp;#8217;ve migrated an application to a &lt;a href=&#34;docker.io&#34;&gt;docker&lt;/a&gt; based development environment and used this c3p0 feature with &lt;a href=&#34;http://docs.docker.io/en/latest/use/working_with_links_names/&#34;&gt;docker links&lt;/a&gt; to set mysql settings:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;app {
 db {
  host = localhost
  host = ${?DB_PORT_3306_TCP_ADDR}
  port = &amp;quot;3306&amp;quot;
  port = ${?DB_PORT_3306_TCP_PORT}
 }
}

c3p0 {
 named-configs {
  myapp {
      jdbcUrl = &amp;quot;jdbc:mysql://&amp;quot;${app.db.host}&amp;quot;:&amp;quot;${app.db.port}&amp;quot;/MyDatabase&amp;quot;
  }
 }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When I link a mysql container to my app container with &lt;code&gt;--link mysql:db&lt;/code&gt; Docker will inject the DB_PORT_3306_TCP_* environment variables which are pulled by the above settings.&lt;/p&gt;

&lt;h3 id=&#34;accessing-values-from-code:25b0f7af66c88453ba07c790c20bec8d&#34;&gt;Accessing Values From Code&lt;/h3&gt;

&lt;p&gt;One other practice I like is having a single &amp;#8220;Config&amp;#8221; class for an application. It can be very tempting to load a configuration node from anywhere in your app but that can get messy fast. Instead, create a config class and access everything you need through that:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;object MyAppConfig {
  private val config =  ConfigFactory.load()

  private lazy val root = config.getConfig(&amp;quot;my_app&amp;quot;)

  object HttpConfig {
    private val httpConfig = config.getConfig(&amp;quot;http&amp;quot;)

    lazy val interface = httpConfig.getString(&amp;quot;interface&amp;quot;)
    lazy val port = httpConfig.getInt(&amp;quot;port&amp;quot;)
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Type safety, Single Responsibility, and no strings all over the place.&lt;/p&gt;

&lt;h3 id=&#34;conclusion:25b0f7af66c88453ba07c790c20bec8d&#34;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;When dealing with configuration think about what environments you have and what the actual differences are between those environments. Usually this is a small set of differing values for only a few properties. Make it easy to change just those settings without changing&amp;#8211;or duplicating&amp;#8211;anything else. This could done via environment variables, command line flags, even loading configuration files from a url. Definitely avoid copying the same value across multiple configurations: just distill that value down to a lower setting in a hierarchy. By minimizing configuration files you&amp;#8217;ll be making your life a lot easier.&lt;/p&gt;

&lt;p&gt;If you&amp;#8217;re developing an app for distribution, or writing a library, providing a well-documented configuration file (&lt;a href=&#34;https://github.com/spray/spray/blob/master/spray-can/src/main/resources/reference.conf&#34;&gt;spray&amp;#8217;s spray-can reference.conf is an excellent example&lt;/a&gt;) you can allow users to override defaults easily in a manner that is suitable for them and their runtimes.&lt;/p&gt;
</description>
        </item>
      
    

  </channel>
</rss>
