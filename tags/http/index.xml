<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> </title>
    <link>http://blog.michaelhamrah.com/tags/http/</link>
    <language>en-us</language>
    <author>Michael Hamrah</author>
    <rights>(C) 2015</rights>
    <updated>2014-05-24 00:00:00 &#43;0000 UTC</updated>

    
      
        <item>
          <title>Spray Directives: Creating Your Own, Simple Directive</title>
          <link>http://blog.michaelhamrah.com/2014/05/spray-directives-creating-your-own-simple-directive/</link>
          <pubDate>Sat, 24 May 2014 00:00:00 UTC</pubDate>
          <author>Michael Hamrah</author>
          <guid>http://blog.michaelhamrah.com/2014/05/spray-directives-creating-your-own-simple-directive/</guid>
          <description>&lt;p&gt;The &lt;a href=&#34;http://spray.io/documentation/1.2.1/spray-routing/&#34;&gt;spray-routing&lt;/a&gt; package provides an excellent dsl for creating restful api&amp;#8217;s with Scala and Akka. This dsl is powered by &lt;a href=&#34;http://spray.io/documentation/1.2.1/spray-routing/key-concepts/directives/&#34;&gt;directives&lt;/a&gt;, small building blocks you compose to filter, process and compose requests and responses for your API. Building your own directives lets you create reusable components for your application and better organize your application.&lt;/p&gt;

&lt;p&gt;I recently refactored some code in a Spray API to leverage custom directives. The &lt;a href=&#34;http://spray.io/documentation/1.2.1/spray-routing/advanced-topics/custom-directives/&#34;&gt;Spray documentation provides a good reference on custom directives&lt;/a&gt; but I found myself getting hung up in a few places.&lt;/p&gt;

&lt;p&gt;As an example we&amp;#8217;re going to write a custom directive which produces a UUID for each request. Here&amp;#8217;s how I want to use this custom directive:&lt;/p&gt;

&lt;pre class=&#34;syntax scala&#34;&gt;generateUUID { uuid =&gt;
  path(&#34;foo&#34;) {
   get {
     //log the uuid, pass it to your app, or maybe just return it
     complete { uuid.toString }
   }
  }
}
&lt;/pre&gt;

&lt;p&gt;Usually you leverage existing directives to build custom directives. I (incorrectly) started with the &lt;code&gt;provide&lt;/code&gt; directive to provide a value to an inner route:&lt;/p&gt;

&lt;pre class=&#34;syntax scala&#34;&gt;import spray.routing._
import java.util.UUID
import Directives._

trait UuidDirectives {
  def generateUuid: Directive1[UUID] = {
    provide(UUID.randomUUID)
  }
}
&lt;/pre&gt;

&lt;p&gt;Before I explain what&amp;#8217;s wrong, let&amp;#8217;s dig into the code. First, generateUuid is a function which returns a Directive1 wrapping a UUID value. Directive1 is just a type alias for &lt;code&gt;Directive[UUID :: HNil]&lt;/code&gt;. Directives are centered around a feature of the shapeless library called heterogeneous lists, or HLists. An &lt;code&gt;HList&lt;/code&gt; is simply a list, but each element in the list can be a different, specific type. Instead of a generic &lt;code&gt;List[Any]&lt;/code&gt;, your list can be composed of specific types of list of String, Int, String, UUID. The first element of this list is a String, not an Any, and the second is an Int, with all the features of an Int. In the directive above I just have an &lt;code&gt;HList&lt;/code&gt; with one element: &lt;code&gt;UUID&lt;/code&gt;. If I write &lt;code&gt;Directive[UUID :: String :: HNil]&lt;/code&gt; I have a two element list of &lt;code&gt;UUID&lt;/code&gt; and String, and the compiler will throw an error if I try to use this directive with anything other a &lt;code&gt;UUID&lt;/code&gt; and a String. HLists sound like a lightweight case class, but with an &lt;code&gt;HList&lt;/code&gt;, you get a lot of list-like features. HLists allow the compiler to do the heavy lifting of type safety, so you can have strongly-typed functions to compose together.&lt;/p&gt;

&lt;p&gt;Provide is a directive which (surprise surprise) will provide a value to an inner route. I thought this would be perfect for my directive, and the corresponding test ensures it works:&lt;/p&gt;

&lt;pre class=&#34;syntax scala&#34;&gt;import org.scalatest._
import org.scalatest.matchers._
import spray.testkit.ScalatestRouteTest
import spray.http._
import spray.routing.Directives._

class UuidDirectivesSpec
  extends FreeSpec
  with Matchers
  with UuidDirectives
  with ScalatestRouteTest {

  &#34;The UUID Directive&#34; - {
    &#34;can generate a UUID&#34; in {
      Get() ~&gt; generateUuid { uuid =&gt; complete(uuid.toString) } ~&gt; check  {
        responseAs[String].size shouldBe 36
      }
    }
  }
}
&lt;/pre&gt;

&lt;p&gt;But there&amp;#8217;s an issue! Spray directives are classes are composed when instantiated via an apply() function. The &lt;a href=&#34;http://spray.io/documentation/1.2.1/spray-routing/advanced-topics/understanding-dsl-structure/&#34;&gt;Spray docs on understanding the dsl structure&lt;/a&gt; explains it best, but in summary, generateUuid will only be called once when the routing tree is built, not on every request.&lt;/p&gt;

&lt;p&gt;A better unit test shows the issue:&lt;/p&gt;

&lt;pre class=&#34;syntax scala&#34;&gt;&#34;will generate different UUID per request&#34; in {
      //like the runtime, instantiate route once
      val uuidRoute =  generateUuid { uuid =&gt; complete(uuid.toString) }

      var uuid1: String = &#34;&#34;
      var uuid2: String = &#34;&#34;
      Get() ~&gt; uuidRoute ~&gt; check  {
        responseAs[String].size shouldBe 36
        uuid1 = responseAs[String]
      }
      Get() ~&gt; uuidRoute ~&gt; check  {
        responseAs[String].size shouldBe 36
        uuid2 = responseAs[String]
      }
      //fails!
      uuid1 shouldNot equal (uuid2)
    }
  }
&lt;/pre&gt;

&lt;p&gt;The fix is simple: we need to use the &lt;code&gt;extract&lt;/code&gt; directive which applies the current RequestContext to our route so it&amp;#8217;s called on every request. For our UUID directive we don&amp;#8217;t need anything from the request, just the function which is run for every request:&lt;/p&gt;

&lt;pre class=&#34;syntax scala&#34;&gt;trait UuidDirectives {
  def generateUuid: Directive[UUID :: HNil] = {
    extract(ctx =&gt;
        UUID.randomUUID)
  }
}
&lt;/pre&gt;

&lt;p&gt;With our randomUUID call wrapped in an extract directive we have a unique call per request, and our tests pass!&lt;/p&gt;

&lt;p&gt;In a following post we&amp;#8217;ll add some more complexity to our custom directive, stay tuned!&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Spray Directives: Custom Directives, Part Two: flatMap</title>
          <link>http://blog.michaelhamrah.com/2014/05/spray-directives-custom-directives-part-two-flatmap/</link>
          <pubDate>Sat, 24 May 2014 00:00:00 UTC</pubDate>
          <author>Michael Hamrah</author>
          <guid>http://blog.michaelhamrah.com/2014/05/spray-directives-custom-directives-part-two-flatmap/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;http://blog.michaelhamrah.com/2014/05/spray-directives-creating-your-own-simple-directive/&#34;&gt;Our last post covered custom Spray Directives&lt;/a&gt;. We&amp;#8217;re going to expand our UUID directive a little further. Generating a unique ID per request is great, but what if we want the client to pass in an existing unique identifier to act as a correlation id between systems?&lt;/p&gt;

&lt;p&gt;We&amp;#8217;ll modify our existing directive by checking to see if the client supplied a correlation-id request-header using the existing &lt;code&gt;optionalHeaderValueByName&lt;/code&gt; directive:&lt;/p&gt;

&lt;pre class=&#34;syntax scala&#34;&gt;def generateUuid: Directive[UUID :: HNil] = {
    optionalHeaderValueByName(&#34;correlation-id&#34;) {
      case Some(value) =&gt; provide(UUID.fromString(value))
      case None =&gt; provide(UUID.randomUUID)
    }
  }
&lt;/pre&gt;

&lt;p&gt;Unfortunately this code doesn&amp;#8217;t compile! We get an error because Spray is looking for a Route, which is a function of RequestContext =&amp;gt; Unit:&lt;/p&gt;

&lt;pre class=&#34;syntax bash&#34;&gt;[error]  found   : spray.routing.Directive1
[error]     (which expands to)  spray.routing.Directive[shapeless.::]
[error]  required: spray.routing.RequestContext =&gt; Unit
[error]       case Some(value) =&gt; provide(UUID.fromString(value))
&lt;/pre&gt;

&lt;p&gt;What do we do? &lt;code&gt;flatMap&lt;/code&gt; comes to the rescue. Here&amp;#8217;s the deal: we need to transform one directive (&lt;code&gt;optionalHeaderValueByName&lt;/code&gt;) into another directive (one that provides a UUID). We do this by using flatMap to focus on the value in the first directive (the option returned from &lt;code&gt;optionalHeaderValueByName&lt;/code&gt;) and return another value (the UUID). With &lt;code&gt;flatMap&lt;/code&gt; we are basically &amp;#8220;repackaging&amp;#8221; one value into another package.&lt;/p&gt;

&lt;p&gt;Here&amp;#8217;s the updated code which properly compiles:&lt;/p&gt;

&lt;pre class=&#34;syntax scala&#34;&gt;def generateUuid: Directive[UUID :: HNil] = {
    //use flatMap to match on the Option returned and provide
    //a new value
    optionalHeaderValueByName(&#34;correlation-id&#34;).flatMap {
      case Some(value) =&gt; provide(UUID.fromString(value))
      case None =&gt; provide(UUID.randomUUID)
    }
  }
&lt;/pre&gt;

&lt;p&gt;and the test:&lt;/p&gt;

&lt;pre class=&#34;syntax scala&#34;&gt;&#34;can extract a uuid value from the header&#34; in {
      val uuid = java.util.UUID.randomUUID.toString

      Get() ~&gt; addHeader(&#34;correlation-id&#34;, uuid) ~&gt; uuidRoute ~&gt; check {
        responseAs[String] shouldEqual uuid
      }
    }
&lt;/pre&gt;

&lt;p&gt;There&amp;#8217;s a small tweak we&amp;#8217;ll make to our UUID directive to show another example of directive composition. If the client doesn&amp;#8217;t supply a UUID, and we call generateUUID multiple times, we&amp;#8217;ll get different uuids for the same request. This defeats the purpose of a single correlation id, and prevents us from extracting a uuid multiple times per request. A failing test shows the issue:&lt;/p&gt;

&lt;pre class=&#34;syntax scala&#34;&gt;&#34;can extract the same uuid twice per request&#34; in {
      var uuid1: String =&#34;&#34;
      var uuid2: String = &#34;&#34;
      Get() ~&gt; generateUuid { uuid =&gt;
        {
          uuid1 = uuid.toString
          generateUuid { another =&gt;
            uuid2 = another.toString
            complete(&#34;&#34;)
          }
        }
      } ~&gt; check {
        //fails
        uuid1 shouldEqual uuid2
      }
    }
&lt;/pre&gt;

&lt;p&gt;To fix the issue, if we generate a UUID, we will add it to the request header as if the client supplied it. We&amp;#8217;ll use the mapRequest directive to add the generated UUID to the header.&lt;/p&gt;

&lt;pre class=&#34;syntax scala&#34;&gt;def generateUuid: Directive[UUID :: HNil] = {
    optionalHeaderValueByName(&#34;correlation-id&#34;).flatMap {
      case Some(value) =&gt; provide(UUID.fromString(value))
      case None =&gt;
        val id = UUID.randomUUID
        mapRequest(r =&gt; r.withHeaders(r.headers :+ RawHeader(&#34;correlation-id&#34;, id.toString))) &amp;#038; provide(id)
    }
  }
&lt;/pre&gt;

&lt;p&gt;In my first version I had the mapRequest call and the provide call on separate lines (there was no &amp;amp;). mapRequest was never being called, and it was because mapRequest was not being returned as a value- only the provide directive is returned. We need to &amp;#8220;merge&amp;#8221; these two directives with the &amp;amp; operator. &lt;code&gt;mapRequest&lt;/code&gt; is a no-op returning a Directive0 (a Directive with a Nil HList) so combining it with provide yields a Directive1[UUID], which is exactly what we want.&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>How to Handle a Super Bowl Size Spike in Web Traffic</title>
          <link>http://blog.michaelhamrah.com/2013/02/how-to-handle-a-super-bowl-size-spike-in-web-traffic/</link>
          <pubDate>Wed, 06 Feb 2013 00:00:00 UTC</pubDate>
          <author>Michael Hamrah</author>
          <guid>http://blog.michaelhamrah.com/2013/02/how-to-handle-a-super-bowl-size-spike-in-web-traffic/</guid>
          <description>

&lt;p&gt;I was shocked to learn the number of &lt;a href=&#34;http://www.yottaa.com/blog/bid/265815/Coke-SodaStream-the-13-Websites-That-Crashed-During-Super-Bowl-2013&#34;&gt;sites which failed to handle the spike in web traffic during the Super Bowl&lt;/a&gt;. Most of these sites served static content and should have scaled easily with the use of CDNs. Scaling sites, even dynamic ones, are achievable with well known tools and techniques.&lt;/p&gt;

&lt;h2 id=&#34;the-problem-is-simple:9da68d5a6f235e570e3d7349e289ad5f&#34;&gt;The Problem is Simple&lt;/h2&gt;

&lt;p&gt;At a basic level accessing a web page is when one computer, the client, connects to a server and downloads some content. A problem occurs when the number of people requesting content exceeds the ability to deliver content. It&amp;#8217;s just like a restaurant. When there are too many customers people must wait to be served. Staff becomes stressed and strained. Computers are the same. Excessive load causes things to break down.&lt;/p&gt;

&lt;h2 id=&#34;optimization-comes-in-three-forms:9da68d5a6f235e570e3d7349e289ad5f&#34;&gt;Optimization Comes in Three Forms&lt;/h2&gt;

&lt;p&gt;To handle more requests there are three things you can do: produce (render) content faster, deliver (download) content faster and add more servers to handle more connections. Each of these solutions has a limit. Designing for these limits is architecting for scale.&lt;/p&gt;

&lt;p&gt;A page is composed of different types of content: html, css and js. This content is either dynamic (changes frequently) or static (changes infrequently). Static content is easier to scale because you create it once and deliver it repeatedly. The work of rendering is eliminated. Static content can be pushed out to CDNs or cached locally to avoid redownloading. Requests to origin servers are reduced or eliminated. You can also download content faster with small payload sizes. There is less to deliver if there is less markup and the content is compressed. Less to deliver means faster download.&lt;/p&gt;

&lt;p&gt;Dynamic content is trickier to cache because it is always changing. Reuse is difficult because pages must be regenerated for specific users at specific times. Scaling dynamic content involves database tuning, server side caching, and code optimization. If you can render a page quickly you can deliver more pages because the server can move on to new requests. Most often, at scale, you want to treat treat dynamic content like static content as best you can.&lt;/p&gt;

&lt;p&gt;Adding more servers is usually the easiest way to scale but breaks down quickly. The more servers you have the more you need to keep in sync and manage. You may be able to add more web servers, but those web servers must connect to database servers. Even powerful database servers can only handle so many connections and adding multiple database servers is complicated. You may be able to add specific types of servers, like cache servers, to achieve the results you need without increasing your entire topology.&lt;/p&gt;

&lt;p&gt;The more servers you have the harder it is to keep content fresh. You may feel increasing your servers will increase your load. It will become expensive to both manage and run. You may be able to achieve a similar result if you cut your response times which also gives the end user a better experience. If you understand the knobs and dials of your system you can tune properly.&lt;/p&gt;

&lt;h2 id=&#34;make-assumptions:9da68d5a6f235e570e3d7349e289ad5f&#34;&gt;Make Assumptions&lt;/h2&gt;

&lt;p&gt;Don&amp;#8217;t be afraid to make assumptions about your traffic patterns. This will help you optimize for your particular situation. For most publicly facing websites traffic is anonymous. This is particularly true during spikes like the Super Bowl. Because you can deliver the same page to every anonymous user you effectively have static content for those users. Cache controls determine how long content is valid and powers HTTP accelerators and CDNs for distribution. You don&amp;#8217;t need to optimize for everyone; split your user base into groups and optimize for the majority. Even laxing cache rules on pages to a minute can shift the burden away from your application servers freeing valuable resources. Anonymous users will get the benefit of cached content with a quick download, dynamic users will have fast servers.&lt;/p&gt;

&lt;p&gt;You can also create specific rendering pipelines for anonymous and known users for highly dynamic content. If you can identify anonymous users early you may be able to avoid costly database queries, external API calls or page renders.&lt;/p&gt;

&lt;h2 id=&#34;understand-http:9da68d5a6f235e570e3d7349e289ad5f&#34;&gt;Understand HTTP&lt;/h2&gt;

&lt;p&gt;HTTP powers the web. The better you understand HTTP the better you can leverage tools for optimizing the web. Specifically look at &lt;a href=&#34;http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html&#34;&gt;http cache headers&lt;/a&gt; which allow you to use web accelerators like Varnish and CDNs. The vary header will allow you to split anonymous and known users giving you fine grained control on who gets what. Expiration headers determine content freshness. The worst thing you can do is set cache headers to private on static content preventing browsers from caching locally.&lt;/p&gt;

&lt;h2 id=&#34;try-varnish-and-esi:9da68d5a6f235e570e3d7349e289ad5f&#34;&gt;Try Varnish and ESI&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.varnish-cache.org&#34;&gt;Varnish&lt;/a&gt; is an HTTP accelerator. It caches dynamic content produced from your website for efficient delivery. Web frameworks usually have their own features for caching content, but Varnish allows you to bypass your application stack completely for faster response times. You can deliver a pre-rendered dynamic page as if it were a static page sitting in memory for a greater number of connections.&lt;/p&gt;

&lt;p&gt;Edge Side Includes allow you to mix static and dynamic content together. If a page is 90% similar for everyone, you can cache the 90% in Varnish and have your application server deliver the other 10%. This greatly reduces the work your app server needs to do. ESI&amp;#8217;s are just emerging into web frameworks. It will play a more prominent role in Rails 4.&lt;/p&gt;

&lt;h2 id=&#34;use-a-cdn-and-multiple-data-centers:9da68d5a6f235e570e3d7349e289ad5f&#34;&gt;Use a CDN and Multiple Data Centers&lt;/h2&gt;

&lt;p&gt;You don&amp;#8217;t need to add more servers to your own data center. You can leverage the web to fan work out across the Internet. I talk more about CDN&amp;#8217;s, the importance of edge locations and latency in my post &lt;a href=&#34;http://www.michaelhamrah.com/blog/2012/01/building-for-the-web-understanding-the-network/&#34;&gt;Building for the Web: Understanding the Network&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Your application servers should be reserved for doing application-specific work which is unique to every request. There are more efficient ways of delivering the same content to multiple people than processing a request top-to-bottom via a web framework. Remember &amp;#8220;the same&amp;#8221; doesn&amp;#8217;t mean the same indefinitely; it&amp;#8217;s the same for whatever timeframe you specify.&lt;/p&gt;

&lt;p&gt;If you run Varnish servers in multiple data centers you can effectively create your own CDN. Your database and content may be on the east coast but if you run a Varnish server on the west coast an anonymous user in San Fransisco will have the benefit of a fast response time and you&amp;#8217;ve saved a connection to your app server. Even if Varnish has to deliver 10% dynamic content via an ESI on the east coast it can leverage the fast connection between data centers. This is much better then the end user hoping coast-to-coast themselves for an entire page.&lt;/p&gt;

&lt;p&gt;Amazon&amp;#8217;s Route 53 offers the ability to route requests to an optimal location. There are other geo-aware DNS solutions. If you have a multi-region setup you are not only building for resiliency your are horizontally scaling your requests across data centers. At massive scale even load balancers may become overloaded so round-robin via DNS becomes essential. DNS may be a bottleneck as well. If your DNS provider can&amp;#8217;t handle the flood of requests trying to map your URL to your IP address nobody can even get to your data center!&lt;/p&gt;

&lt;h2 id=&#34;use-auto-scaling-groups-or-alerting:9da68d5a6f235e570e3d7349e289ad5f&#34;&gt;Use Auto Scaling Groups or Alerting&lt;/h2&gt;

&lt;p&gt;If you can take an action when things get rough you can better handle spikes. Auto scaling groups are a great feature of AWS when some threshold is maxed. If you&amp;#8217;re not on AWS good monitoring tools will help you take action when things hit a danger zone. If you design your application with auto-scaling in mind, leveraging load balancers for internal communication and avoiding state, you are in a better position to deal with traffic growth. Scaling on demand saves money as you don&amp;#8217;t need to run all your servers all the time. Pinterest gave a talk explaining how it saves money by reducing its server farm at night when traffic is low.&lt;/p&gt;

&lt;h2 id=&#34;compress-and-serialized-data-across-the-wire:9da68d5a6f235e570e3d7349e289ad5f&#34;&gt;Compress and Serialized Data Across the Wire&lt;/h2&gt;

&lt;p&gt;Page sizes can be greatly reduced if you enable compression. Web traffic is mostly text which is easily compressible. A 100kb page is a lot faster to download than a 1mb page. Don&amp;#8217;t forget about internal communication as well. In todays API driven world using efficient serialization protocols like protocol buffers can greatly reduce network traffic. Most RPC tools support some form of optimal serialization. SOAP was the rage in the early 2000s but XML is one of the worst ways to serialize data for speed. Compressed content allows you to store more in cache and reduces network I/O as well.&lt;/p&gt;

&lt;h2 id=&#34;shut-down-features:9da68d5a6f235e570e3d7349e289ad5f&#34;&gt;Shut Down Features&lt;/h2&gt;

&lt;p&gt;A performance bottleneck may be caused by one particular feature. When developing new features, especially on a high traffic site, the ability to shut down a misbehaving feature could be the quick solution to a bad problem. Most high-traffic websites &amp;#8220;leak&amp;#8221; new features by deploying them to only 10% of their users to monitor behavior. Once everything is okay they activate the feature everywhere. Similar to determining page freshness for caches, determining available features under load can keep a site alive. What&amp;#8217;s more important: one specific feature or the entire system?&lt;/p&gt;

&lt;h2 id=&#34;non-blocking-i-o:9da68d5a6f235e570e3d7349e289ad5f&#34;&gt;Non-Blocking I/O&lt;/h2&gt;

&lt;p&gt;Asynchronous programming is a challenge and probably a last-resort for scaling. Sometimes servers break down without any visible threshold. You may have seen a slow request but memory, cpu, and network levels are all okay. This scenario is usually caused by blocking threads waiting on some form of I/O. Blocked threads are plugs that clog your application. They do nothing and prevent other things from happening. If you call external web services, run long database queries or perform disk I/O beware of synchronous operations. They are bottlenecks. Asynchronous based frameworks like node.js put asynchronous programming at the forefront of development making them attractive for handling numerous concurrent connections. Asynchronous programming also paves the way for queue-based architectures. If every request is routed through a queue and processed by a worker the queue will help even out spikes in traffic. The queue size will also determine how many workers you need. It may be trickier to code but it&amp;#8217;s how things scale.&lt;/p&gt;

&lt;h2 id=&#34;think-at-scale:9da68d5a6f235e570e3d7349e289ad5f&#34;&gt;Think at Scale&lt;/h2&gt;

&lt;p&gt;When dealing with a high-load environment nothing can be off the table. What works for a few thousand users will grow out of control for a few million. Even small issues will become exponentially problematic.&lt;/p&gt;

&lt;p&gt;Scaling isn&amp;#8217;t just about the tools to deal with load. It&amp;#8217;s about the decisions you make on how your application behaves. The most important thing is determining page freshness for users. The decisions for an up-to-the-second experience for every user are a lot different than an up-to-the-minute experience for anonymous users. When dealing with millions of concurrent requests one will involve a lot of engineering complexity and the other can be solved quickly.&lt;/p&gt;
</description>
        </item>
      
    

  </channel>
</rss>
